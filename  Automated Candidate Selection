{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3398,"sourceType":"datasetVersion","datasetId":1980},{"sourceId":3004484,"sourceType":"datasetVersion","datasetId":1840540},{"sourceId":8668279,"sourceType":"datasetVersion","datasetId":5194699},{"sourceId":10639823,"sourceType":"datasetVersion","datasetId":6587565}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Automated Clinical Reasoning","metadata":{}},{"cell_type":"markdown","source":"Intent: Bridge the gap between biological signals (imaging-derived metrics like nWBV) and contextual markers (clinical features like MMSE and FunctionalAssessment).\n\nhttps://www.sciencedirect.com/science/article/pii/S2274580725003395?ref=cra_js_challenge&fr=RR-1","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n\n\n\n#  Data loading\nclinical_path = '/kaggle/input/alzheimers-disease-dataset/alzheimers_disease_data.csv'\noasis_path = '/kaggle/input/mri-and-alzheimers/oasis_cross-sectional.csv'\nimage_directory = '/kaggle/input/alzheimer-mri-4-classes-dataset/Alzheimer_MRI_4_classes_dataset'\n\n\n# Pull Clinical Data\nif os.path.exists(clinical_path):\n    df_clinical = pd.read_csv(clinical_path)\n    # # Stage_Index mapping: 0 (Healthy) vs 1 (Impaired) ensures cross-dataset compatibility.\n    df_clinical['Stage_Index'] = df_clinical['Diagnosis'] \nelse:\n    raise FileNotFoundError(\"Clinical dataset not found.\")\n\n# Pull Structural/Biological Data (OASIS)\nif os.path.exists(oasis_path):\n    df_oasis = pd.read_csv(oasis_path)\n    # nWBV = normalized Whole Brain Volume (Key Biological Signal)\n    mri_metrics = df_oasis[['Age', 'nWBV', 'ASF', 'CDR']]\n    # Harmonizing CDR to Stage_Index\n    df_oasis['Stage_Index'] = df_oasis['CDR'].apply(lambda x: 1 if x > 0 else 0)\n    \n\n# Data Pre-processing \n# Scaling clinical features for neural network convergence\nclinical_features_list = ['Age', 'BMI', 'MMSE', 'FunctionalAssessment']\nscaler = StandardScaler()\ndf_clinical[clinical_features_list] = scaler.fit_transform(df_clinical[clinical_features_list])\n\n# Create the \"Patient Profile Bank\"\n# This allows the AI to pair any image with a clinical profile of the same stage\n## clinical_data_bank serves as a lookup for context sampling, addressing the 5121 vs 2149 row mismatch.\nclinical_data_bank = {\n    0: df_clinical[df_clinical['Stage_Index'] == 0],\n    1: df_clinical[df_clinical['Stage_Index'] == 1]\n}\n\n\n# Standard Image Preprocessing\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\ntrain_generator = train_datagen.flow_from_directory(\n    image_directory,\n    target_size=(128, 128),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training'\n)\n\nprint(f\"Found {train_generator.samples} images belonging to {train_generator.num_classes} classes.\")\n\nprint(f\"--- Data Harmonization Check ---\")\nprint(f\"Clinical Data: Found {len(df_clinical)} rows.\")\nprint(f\"Clinical Stage Distribution:\\n{df_clinical['Stage_Index'].value_counts()}\")\n\n\nif 'mri_metrics' in locals():\n    print(f\"\\nOASIS Structural Data: Found {len(mri_metrics)} rows.\")\n    # Check nWBV (the biological signal highlighted in the paper)\n    print(f\"Average nWBV (Whole Brain Volume): {mri_metrics['nWBV'].mean():.4f}\")\n\n# Check the distribution of the Stage_Index\nstage_counts = df_clinical['Stage_Index'].value_counts()\nprint(f\"Patient Profiles in Bank: Stage 0 (Healthy): {stage_counts[0]} | Stage 1 (Impaired): {stage_counts[1]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Multimodal Data Generator","metadata":{}},{"cell_type":"code","source":"# Bridges the mismatch between 2,149 clinical rows and MRI folders\n\ndef multimodal_generator(image_gen, clinical_bank):\n    while True:\n        img_batch, label_batch = next(image_gen)\n        clin_batch = np.zeros((img_batch.shape[0], 4))\n        \n        for i in range(img_batch.shape[0]):\n            class_idx = np.argmax(label_batch[i])\n            stage = 0 if class_idx == 2 else 1\n            \n            sample = clinical_bank[stage].sample(1)\n            clin_batch[i] = sample[['Age', 'BMI', 'MMSE', 'FunctionalAssessment']].values\n            \n        # FIX: Yield as a tuple ( (input1, input2), labels ) instead of a list\n        yield (img_batch, clin_batch), label_batch\n\nprint(f\"\\n--- IMAGE INGESTION ---\")\n# This triggers the folder scan\nprint(f\"Found Classes: {train_generator.class_indices}\")\nprint(f\"Total MRI Training Images: {train_generator.samples}\")\nprint(f\"Batch Size: {train_generator.batch_size}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize the multimodal stream\ntrain_multi_gen = multimodal_generator(train_generator, clinical_data_bank)\n\n# Pull a batch\n(imgs, clins), lbls = next(train_multi_gen)\n\nprint(f\"Multimodal Bridge Active\")\nprint(f\"MRI Shape: {imgs.shape} (Biological)\")\nprint(f\"Clinical Shape: {clins.shape} (Contextual)\")\nprint(f\"First clinical profile in batch: {clins[0]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## The Two Tower MultiModal Model (Image and Clinical Tower)","metadata":{}},{"cell_type":"code","source":"def build_goldilocks_model(num_classes):\n## Tower 1 (Biological): Uses GAP and Dense layers to compress MRI features into a latent vector.\n\n# Tower 2 (Contextual): Processes low-dimensional cognitive markers (MMSE, BMI, etc.).\n\n# Embedding Space: The fusion layer where the 'Goldilocks' score to be calculated.\n    \n    # Tower 1: Biological Signal (MRI Structural Evidence)\n    image_input = layers.Input(shape=(128, 128, 3), name=\"mri_input\")\n    x = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dense(64, activation='relu')(x)\n\n    # Tower 2: Contextual Signal (Cognitive & Functional Assessment)\n    clin_input = layers.Input(shape=(4,), name=\"clinical_input\")\n    y = layers.Dense(16, activation='relu')(clin_input)\n    y = layers.Dense(16, activation='relu')(y)\n\n    # Fusion Layer: Creates the Stage-by-Subtype Probability Map\n    merged = layers.Concatenate()([x, y])\n    embedding = layers.Dense(64, activation='relu', name=\"embedding_space\")(merged)\n    \n    # Final Diagnosis Output\n    output = layers.Dense(num_classes, activation='softmax')(embedding)\n\n    model = models.Model(inputs=[image_input, clin_input], outputs=output)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\nCLASSES = ['Non Demented', 'Very mild Dementia', 'Mild Dementia', 'Moderate Dementia']\nmodel = build_goldilocks_model(len(CLASSES))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Verification","metadata":{}},{"cell_type":"code","source":"print(\"\\n--- Multimodal Verification ---\")\n(imgs, clins), lbls = next(train_multi_gen)\nprint(f\"MRI Batch: {imgs.shape} | Clinical Batch: {clins.shape}\") # Expect (32, 128, 128, 3) and (32, 4)\nprint(f\"Sample Clinical Pair (Age, BMI, MMSE, Func): {clins[0]}\")\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prediction Variance","metadata":{}},{"cell_type":"code","source":"# Create the generator\ntrain_multi_gen = multimodal_generator(train_generator, clinical_data_bank)\n\n# Start training with the bridge\nhistory = model.fit(\n    train_multi_gen,\n    steps_per_epoch=len(train_generator),\n    epochs=10,\n    verbose=1\n)\n\nprint(\"\\n--- Training Progress ---\")\nprint(f\"Final Accuracy: {history.history['accuracy'][-1]:.4f}\")\nprint(f\"Final Loss:     {history.history['loss'][-1]:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prognostic Mapping","metadata":{}},{"cell_type":"markdown","source":"The \"Goldilocks Zone\": Within this space, the \"Goldilocks Zone\" is a specific geographic region where the biological and clinical markers are \"just right\" for a trial. This region identifies patients who are at the peak window for treatment—not so healthy that they show no change, and not so advanced that the disease is irreversible.","metadata":{}},{"cell_type":"code","source":"# Extract the Embedding Space to visualize the Goldilocks clusters\nembedding_model = models.Model(inputs=model.input, outputs=model.get_layer('embedding_space').output)\n\n# Get a batch of data\n(test_imgs, test_clins), test_labels = next(train_multi_gen)\nembeddings = embedding_model.predict([test_imgs, test_clins])\n\n# Run t-SNE\ntsne = TSNE(n_components=2, random_state=42)\nvis_dims = tsne.fit_transform(embeddings)\n\n# Plot the map\nplt.figure(figsize=(10, 7))\nplt.scatter(vis_dims[:, 0], vis_dims[:, 1], c=np.argmax(test_labels, axis=1), cmap='viridis')\nplt.title(\"Prognostic Space: Mapping the Goldilocks Zone\")\nplt.colorbar(label=\"Dementia Stage\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Identifying Goldilocks Candidates","metadata":{}},{"cell_type":"markdown","source":"A patient \"Goldilocks Candidate\" when their multimodal embedding—their unique combination of brain volume and cognitive scores—places them directly inside the identified Goldilocks Zone of the map.","metadata":{}},{"cell_type":"code","source":"# Extract the Embedding Space to visualize Goldilocks clusters\nembedding_model = models.Model(inputs=model.input, outputs=model.get_layer('embedding_space').output)\n\n# Run t-SNE to map Stage vs. Subtype trajectories\n(test_imgs, test_clins), test_labels = next(train_multi_gen)\nembeddings = embedding_model.predict([test_imgs, test_clins])\ntsne_results = TSNE(n_components=2).fit_transform(embeddings)\n\nplt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=np.argmax(test_labels, axis=1))\nplt.title(\"Prognostic Space Mapping: Identifying Goldilocks Candidates\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.spatial.distance import cdist\n\n\n# Extract the Embedding Space\nembedding_model = models.Model(inputs=model.input, outputs=model.get_layer('embedding_space').output)\n\n# Pull a batch and predict\n(imgs, clins), lbls = next(train_multi_gen)\nembeddings = embedding_model.predict([imgs, clins])\n\n# Calculate 'Moderate' Centroid (The Anchor)\nmod_mask = np.argmax(lbls, axis=1) == 1 \nif not np.any(mod_mask):\n    print(\"Warning: No Moderate patients in this batch. Results may be inaccurate.\")\n    mod_centroid = np.zeros(embeddings.shape[1]) # Fallback\nelse:\n    mod_centroid = embeddings[mod_mask].mean(axis=0)\n\n# Filter for Potential Candidates (Mild/Very Mild)\ncandidate_mask = (np.argmax(lbls, axis=1) == 0) | (np.argmax(lbls, axis=1) == 3)\ncandidate_indices = np.where(candidate_mask)[0]\ncandidate_embeddings = embeddings[candidate_mask]\n\n# Rank by distance to find the Goldilocks candidates\ndistances = cdist(candidate_embeddings, [mod_centroid], metric='euclidean').flatten()\ngoldilocks_rank = np.argsort(distances)[:10]\nfinal_indices = candidate_indices[goldilocks_rank]\n\n# INVERSE TRANSFORM to real units\nreal_values = scaler.inverse_transform(clins[final_indices])\n\n# Create Results Table\nfeature_names = ['Age', 'BMI', 'MMSE', 'FunctionalAssessment']\nresults = []\nfor i, idx in enumerate(final_indices):\n    label_idx = np.argmax(lbls[idx])\n    label_name = {0:'Mild', 1:'Moderate', 2:'NonDemented', 3:'VeryMild'}[label_idx]\n    patient_data = [label_name] + [round(val, 2) for val in real_values[i]]\n    results.append(patient_data)\n\ndf_goldilocks = pd.DataFrame(results, columns=['Clinical Label'] + feature_names)\n\nprint(\"--- GOLDILOCKS CANDIDATE PROFILES ---\")\ndisplay(df_goldilocks)\n\n# Visualize MRI Slices\nplt.figure(figsize=(20, 8))\nplt.suptitle(\"Biological Signals of Goldilocks Candidates (MRI Slices)\", fontsize=16)\n\nfor i, idx in enumerate(final_indices):\n    plt.subplot(2, 5, i + 1)\n    plt.imshow(imgs[idx][:, :, 0], cmap='bone') \n    # FIXED: Using df_goldilocks instead of df_candidates\n    plt.title(f\"Candidate {i+1}\\nLabel: {df_goldilocks.iloc[i]['Clinical Label']}\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Force-syncing the ecosystem to resolve internal namespace conflicts\n!pip install -q -U --force-reinstall --no-cache-dir \\\n    transformers \\\n    accelerate \\\n    bitsandbytes \\\n    huggingface_hub","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import huggingface_hub, transformers, accelerate, bitsandbytes\n\nprint(f\"{'Library':<20} | {'Version'}\")\nprint(\"-\" * 22)\nprint(f\"{'Pandas':<20} | {pd.__version__}\")\nprint(f\"{'NumPy':<20} | {np.__version__}\")\nprint(f\"{'TensorFlow':<20} | {tf.__version__}\")\nprint(f\"{'Matplotlib':<20} | {plt.matplotlib.__version__}\")\nprint(\"-\" * 35)\nprint(f\"{'PyTorch':<20} | {torch.__version__}\")\nprint(f\"{'Transformers':<20} | {transformers.__version__}\")\nprint(f\"{'Accelerate':<20} | {accelerate.__version__}\")\nprint(f\"{'BitsAndBytes':<20} | {bitsandbytes.__version__}\")\nprint(f\"{'HuggingFace Hub':<20} | {huggingface_hub.__version__}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import AutoProcessor, AutoModelForImageTextToText, BitsAndBytesConfig\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nimport bitsandbytes\n\n# 1. AUTHENTICATION & MODEL LOADING\n\nimport torch\nimport warnings\n# We use the high-level Auto classes which are most stable across versions\nfrom transformers import AutoProcessor, AutoModelForImageTextToText, BitsAndBytesConfig\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\n# 1. AUTHENTICATION\nuser_secrets = UserSecretsClient()\ntry:\n    hf_token = user_secrets.get_secret(\"HuggingFace\")\n    if hf_token: login(token=hf_token)\nexcept: pass\n\n# 2. MODEL LOADING (Optimized for T4 GPU)\nmodel_id = \"google/medgemma-1.5-4b-it\"\n\nq_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True\n)\n\nprint(\"Loading MedGemma...\")\nprocessor = AutoProcessor.from_pretrained(model_id)\nreasoning_model = AutoModelForImageTextToText.from_pretrained(\n    model_id,\n    quantization_config=q_config,\n    device_map=\"auto\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_medgemma_reasoning(idx, patient_df, image_batch):\n    \"\"\"\n    Feeds the MRI and clinical data to MedGemma to explain the 'Goldilocks' selection.\n    \"\"\"\n    patient = patient_df.iloc[idx]\n    \n    # Construct the prompt\n    prompt = f\"\"\"\n    User: <image>\n    This patient is flagged as a 'Goldilocks' candidate for a dementia clinical trial.\n    Clinical Profile:\n    - Age: {patient['Age']}\n    - MMSE: {patient['MMSE']} (Clinical Stage: {patient['Clinical Label']})\n    - Functional Assessment: {patient['FunctionalAssessment']}\n    \n    The AI detectes a mismatch: their brain structure (shown in MRI) indicates more advanced \n    neurodegeneration than their cognitive scores suggest. \n    Explain why this patient is an ideal 'imminent progressor' for a drug trial.\n    Assistant: \"\"\"\n\n    # Prepare image (taking the middle slice from your imgs batch)\n    mri_slice = image_batch[idx][:, :, 0] \n    \n    inputs = processor(text=prompt, images=mri_slice, return_tensors=\"pt\").to(\"cuda\")\n    \n    # Generate Reasoning\n    with torch.no_grad():\n        output = reasoning_model.generate(**inputs, max_new_tokens=150)\n    \n    return processor.decode(output[0], skip_special_tokens=True).split(\"Assistant:\")[-1]\n\n# --- EXECUTE REASONING FOR TOP 3 CANDIDATES ---\nprint(\"\\n--- GENERATING MEDGEMMA CLINICAL JUSTIFICATIONS ---\")\nfor i in range(3):\n    print(f\"\\n[Candidate {i+1} Reasoning]:\")\n    reasoning = get_medgemma_reasoning(i, df_goldilocks, imgs)\n    print(reasoning)\n    print(\"-\" * 10)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}