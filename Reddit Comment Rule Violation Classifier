{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":282742,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":239467,"modelId":222398},{"sourceId":576164,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":430985,"modelId":446705}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/swapanroy/reddit-comment-rule-violation-classifier?scriptVersionId=263644915\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Reddit Comment Rule Violation Classifier","metadata":{}},{"cell_type":"code","source":"import kagglehub\nimport more_itertools\nimport pandas as pd\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-24T01:24:46.671906Z","iopub.execute_input":"2025-09-24T01:24:46.67215Z","iopub.status.idle":"2025-09-24T01:24:46.676625Z","shell.execute_reply.started":"2025-09-24T01:24:46.672132Z","shell.execute_reply":"2025-09-24T01:24:46.675691Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Download and load model/tokenizer","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"### -----\n##GEMMA_PATH = kagglehub.model_download(\"google/gemma-3/transformers/gemma-3-1b-it\")\n##processor = AutoTokenizer.from_pretrained(GEMMA_PATH)\n##device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n##model = AutoModelForCausalLM.from_pretrained(GEMMA_PATH).to(device)\n##print(model)\n##model.eval()\n####---","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T01:24:46.677755Z","iopub.execute_input":"2025-09-24T01:24:46.678027Z","iopub.status.idle":"2025-09-24T01:24:46.694018Z","shell.execute_reply.started":"2025-09-24T01:24:46.67801Z","shell.execute_reply":"2025-09-24T01:24:46.693423Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"MODEL_NAME = \"Qwen/Qwen3-1.7B\"  # We can use other model sizes like Qwen/Qwen3-8B if you have more resources\n\nprocessor = AutoTokenizer.from_pretrained(MODEL_NAME)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"  # or .to(device) for simple setups\n)\nprint(model)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T01:25:44.547136Z","iopub.execute_input":"2025-09-24T01:25:44.547394Z","iopub.status.idle":"2025-09-24T01:26:27.227015Z","shell.execute_reply.started":"2025-09-24T01:25:44.547376Z","shell.execute_reply":"2025-09-24T01:26:27.226225Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b01850dbb87b4a30ab0cb9ce564b98a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db5c1d0e76a14b91bad4a9a242b3ebfd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23f5f85a30d74654998252005b1f004b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"582c30d9b74246f083057a30780d5c42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d1c078c666c4e3caf49de53188d2329"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c08ea89aedf641ef9855a7e0636436df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fccd9cf4406485b82478f5fdc51b02d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/622M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5050c8d7cdf4d479f8fd97bd81209b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69a2f5d2b63145a1b940dfaaeea8233d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a834b8e9ac2241c4b3b8976a18d96474"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"248ec684b9c04829b1c4dbc0368839b3"}},"metadata":{}},{"name":"stdout","text":"Qwen3ForCausalLM(\n  (model): Qwen3Model(\n    (embed_tokens): Embedding(151936, 2048)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen3DecoderLayer(\n        (self_attn): Qwen3Attention(\n          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n          (k_proj): Linear(in_features=2048, out_features=1024, bias=False)\n          (v_proj): Linear(in_features=2048, out_features=1024, bias=False)\n          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n        )\n        (mlp): Qwen3MLP(\n          (gate_proj): Linear(in_features=2048, out_features=6144, bias=False)\n          (up_proj): Linear(in_features=2048, out_features=6144, bias=False)\n          (down_proj): Linear(in_features=6144, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n        (post_attention_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n      )\n    )\n    (norm): Qwen3RMSNorm((2048,), eps=1e-06)\n    (rotary_emb): Qwen3RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Qwen3ForCausalLM(\n  (model): Qwen3Model(\n    (embed_tokens): Embedding(151936, 2048)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen3DecoderLayer(\n        (self_attn): Qwen3Attention(\n          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n          (k_proj): Linear(in_features=2048, out_features=1024, bias=False)\n          (v_proj): Linear(in_features=2048, out_features=1024, bias=False)\n          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n        )\n        (mlp): Qwen3MLP(\n          (gate_proj): Linear(in_features=2048, out_features=6144, bias=False)\n          (up_proj): Linear(in_features=2048, out_features=6144, bias=False)\n          (down_proj): Linear(in_features=6144, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n        (post_attention_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n      )\n    )\n    (norm): Qwen3RMSNorm((2048,), eps=1e-06)\n    (rotary_emb): Qwen3RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n)"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"## Load TEST Data","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T01:26:28.285447Z","iopub.execute_input":"2025-09-24T01:26:28.28585Z","iopub.status.idle":"2025-09-24T01:26:28.303438Z","shell.execute_reply.started":"2025-09-24T01:26:28.285815Z","shell.execute_reply":"2025-09-24T01:26:28.302662Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"test_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T01:24:46.734594Z","iopub.status.idle":"2025-09-24T01:24:46.734833Z","shell.execute_reply.started":"2025-09-24T01:24:46.734706Z","shell.execute_reply":"2025-09-24T01:24:46.734715Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prompt Building / Few shot learning ","metadata":{}},{"cell_type":"code","source":"def prompt(input: pd.Series):\n    return \"\"\"<start_of_turn>user\nYou are acting as a Reddit moderator for the given subreddit. You are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule \nAS ENFORCED IN THAT SUBREDDIT. Only respond in True/False:\n{rule}\n\n{pos1}\nDecision: True\n\n{neg1}\nDecision: False\n\n{neg2}\nDecision: False\n\n{pos2}\nDecision: True\n\n{body}\n<end_of_turn>\n<start_of_turn>model\n\"\"\".format(\n        sub=input['subreddit'],\n        rule=input['rule'],\n        pos1=\"\\n\".join([\"| \" + x for x in input['positive_example_1'].split('\\n')]),\n        neg1=\"\\n\".join([\"| \" + x for x in input['negative_example_1'].split('\\n')]),\n        neg2=\"\\n\".join([\"| \" + x for x in input['negative_example_2'].split('\\n')]),\n        pos2=\"\\n\".join([\"| \" + x for x in input['positive_example_2'].split('\\n')]),\n        body=\"\\n\".join([\"| \" + x for x in input['body'].split('\\n')])\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T01:26:42.437971Z","iopub.execute_input":"2025-09-24T01:26:42.438254Z","iopub.status.idle":"2025-09-24T01:26:42.444266Z","shell.execute_reply.started":"2025-09-24T01:26:42.438234Z","shell.execute_reply":"2025-09-24T01:26:42.443326Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Ensure True/False exist in tokenizer vocab","metadata":{}},{"cell_type":"code","source":"token_ids = processor.convert_tokens_to_ids(['True', 'False'])\nif any(tid == processor.unk_token_id for tid in token_ids):\n    raise ValueError(\"One of the target classes (True/False) is missing from the vocabulary.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T01:26:51.281435Z","iopub.execute_input":"2025-09-24T01:26:51.281717Z","iopub.status.idle":"2025-09-24T01:26:51.287124Z","shell.execute_reply.started":"2025-09-24T01:26:51.281698Z","shell.execute_reply":"2025-09-24T01:26:51.286462Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"responses = []\n\n# Batch prediction\nfor batch in more_itertools.batched(test_data.iterrows(), 4):\n    prompts = [prompt(x) for _, x in batch]\n    inputs = processor(\n        text=prompts,\n        return_tensors=\"pt\",\n        padding=True,\n        truncation=True,\n        max_length=512\n    ).to(device)\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    # Extract logits for the next predicted token\n    logits = outputs.logits[:, -1, token_ids]\n    probs = torch.softmax(logits, dim=-1)\n\n    # Store probability of \"True\"\n    responses.extend(probs[:, 0].tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T01:26:56.905739Z","iopub.execute_input":"2025-09-24T01:26:56.906052Z","iopub.status.idle":"2025-09-24T01:27:00.40733Z","shell.execute_reply.started":"2025-09-24T01:26:56.90603Z","shell.execute_reply":"2025-09-24T01:27:00.406747Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Submission ","metadata":{}},{"cell_type":"code","source":"my_submission = pd.DataFrame({\n    'row_id': test_data['row_id'].iloc[:len(responses)],\n    'rule_violation': responses\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T01:27:03.993353Z","iopub.execute_input":"2025-09-24T01:27:03.99363Z","iopub.status.idle":"2025-09-24T01:27:03.998307Z","shell.execute_reply.started":"2025-09-24T01:27:03.993602Z","shell.execute_reply":"2025-09-24T01:27:03.997511Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"my_submission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T01:27:06.777181Z","iopub.execute_input":"2025-09-24T01:27:06.777449Z","iopub.status.idle":"2025-09-24T01:27:06.786506Z","shell.execute_reply.started":"2025-09-24T01:27:06.777429Z","shell.execute_reply":"2025-09-24T01:27:06.785911Z"}},"outputs":[],"execution_count":11}]}