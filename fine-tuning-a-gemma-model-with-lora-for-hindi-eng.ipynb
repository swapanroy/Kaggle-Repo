{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10022647,"sourceType":"datasetVersion","datasetId":6171858},{"sourceId":85986,"sourceType":"modelInstanceVersion","modelInstanceId":72246,"modelId":78150}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/swapanroy/fine-tuning-a-gemma-model-with-lora-for-hindi-eng?scriptVersionId=223302407\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Fine-Tuning the Gemma2_instruct_2b_en Model with LoRA for Hindi-English Translation\n\n(Low-Rank Adaptation)","metadata":{}},{"cell_type":"markdown","source":"## Install dependent libraries ","metadata":{}},{"cell_type":"code","source":"!pip install -q -U keras-nlp datasets\n!pip install -q -U keras\nprint(\"Installation Complete\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T20:19:59.806397Z","iopub.execute_input":"2025-02-18T20:19:59.806683Z","iopub.status.idle":"2025-02-18T20:20:20.806619Z","shell.execute_reply.started":"2025-02-18T20:19:59.806627Z","shell.execute_reply":"2025-02-18T20:20:20.805455Z"}},"outputs":[{"name":"stdout","text":"Installation Complete\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import keras\nimport keras_nlp\nimport os\n\n# Set the backend to JAX for efficient tensor computations\nos.environ[\"KERAS_BACKEND\"] = \"jax\"\n# Allocate 95% of available memory to JAX to avoid fragmentation\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.95\"\n\n#KerasNLP is a natural language processing library that works natively with JAX\n\nimport keras_nlp\nimport keras\n\n# Configure Keras to use half-precision floating-point numbers (bfloat16)\n# for faster training and reduced memory usage\n# keras.config.set_floatx(\"bfloat16\")\n\n# Training hyperparameters\ntoken_limit = 254  # Maximum sequence length\nnum_data_limit = 100  # Number of training examples\nlora_name = \"Roy\"  # Name of the LoRA model\nlora_rank = 4  # Rank of the LoRA model\nlr_value = 1e-4  # Learning rate\ntrain_epoch = 20  # Number of training epochs\n#model_id = \"gemma2_instruct_2b_en\"  # Base model ID; ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T00:51:18.466514Z","iopub.execute_input":"2025-02-19T00:51:18.466928Z","iopub.status.idle":"2025-02-19T00:51:31.126843Z","shell.execute_reply.started":"2025-02-19T00:51:18.466882Z","shell.execute_reply":"2025-02-19T00:51:31.126136Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### LOAD Model","metadata":{}},{"cell_type":"code","source":"\nimport time\n\n# Import the GemmaCausalLM model from KerasNLP\n#gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(model_id)\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset('gemma2_instruct_2b_en')\n\n# Print a summary of the model's architecture\ngemma_lm.summary()\n\n# Initialize a variable to track the start time\ntick_start = 0\n\n# Function to start, stop and print the timer\ndef tick():\n    global tick_start\n    tick_start = time.time()\n\ndef tock():\n    print(f\"TOTAL TIME ELAPSED: {time.time() - tick_start:.2f}s\")\n\ndef text_gen(prompt):\n    tick()\n    input = f\"<start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n    output = gemma_lm.generate(input, max_length=token_limit)\n    print(\"\\nGemma output:\")\n    print(output)\n    tock()\n\n# inference before fine-tuning\n\n# Generate text for the first prompt\ntext_gen(\"Do you know Hindi language?\")\n\n# Generate text for the second prompt (in Hindi)\ntext_gen(\"à¤•à¥à¤¯à¤¾ à¤†à¤ª à¤¹à¤¿à¤‚à¤¦à¥€ à¤­à¤¾à¤·à¤¾ à¤œà¤¾à¤¨à¤¤à¥‡ à¤¹à¥ˆà¤‚?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T03:42:46.150846Z","iopub.execute_input":"2025-02-19T03:42:46.151106Z","iopub.status.idle":"2025-02-19T03:44:09.124952Z","shell.execute_reply.started":"2025-02-19T03:42:46.15108Z","shell.execute_reply":"2025-02-19T03:44:09.124083Z"}},"outputs":[{"name":"stderr","text":"normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              â”‚                      Vocab size: \u001b[38;5;34m256,000\u001b[0m â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)                                                  </span>â”ƒ<span style=\"font-weight: bold\">                                   Config </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              â”‚                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ gemma_backbone                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        â”‚   \u001b[38;5;34m2,614,341,888\u001b[0m â”‚ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        â”‚\nâ”‚ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               â”‚                           â”‚                 â”‚ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ token_embedding               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      â”‚     \u001b[38;5;34m589,824,000\u001b[0m â”‚ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”‚ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         â”‚                           â”‚                 â”‚                            â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)                  </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape              </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to               </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ gemma_backbone                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> â”‚ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               â”‚                           â”‚                 â”‚ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ token_embedding               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> â”‚ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         â”‚                           â”‚                 â”‚                            â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1739936629.171297      30 service.cc:145] XLA service 0x5cf9a503fca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1739936629.171352      30 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1739936642.869505      30 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\nGemma output:\n<start_of_turn>user\nDo you know Hindi language?<end_of_turn>\n<start_of_turn>model\nAs an AI, I don't \"know\" languages in the way a human does. I can't speak or understand Hindi in the same way you do. \n\nHowever, I have been trained on a massive dataset of text and code, which includes a significant amount of Hindi. This means I can:\n\n* **Translate** Hindi to English and vice versa.\n* **Generate** text in Hindi, like writing simple sentences or stories.\n* **Identify** Hindi words and phrases.\n* **Answer** questions about Hindi grammar and vocabulary.\n\nSo, while I don't \"know\" Hindi in a human sense, I can still be helpful with it! \n\nHow can I help you with Hindi today? ğŸ˜Š \n<end_of_turn>\nTOTAL TIME ELAPSED: 28.40s\n\nGemma output:\n<start_of_turn>user\nà¤•à¥à¤¯à¤¾ à¤†à¤ª à¤¹à¤¿à¤‚à¤¦à¥€ à¤­à¤¾à¤·à¤¾ à¤œà¤¾à¤¨à¤¤à¥‡ à¤¹à¥ˆà¤‚?<end_of_turn>\n<start_of_turn>model\nà¤¹à¤¾à¤, à¤®à¥ˆà¤‚ à¤¹à¤¿à¤‚à¤¦à¥€ à¤­à¤¾à¤·à¤¾ à¤œà¤¾à¤¨à¤¤à¤¾ à¤¹à¥‚à¤! ğŸ˜Š  \n\nà¤†à¤ª à¤®à¥à¤à¤¸à¥‡ à¤¹à¤¿à¤‚à¤¦à¥€ à¤®à¥‡à¤‚ à¤¬à¤¾à¤¤ à¤•à¤° à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤ à¤†à¤ª à¤®à¥à¤à¥‡ à¤•à¥à¤¯à¤¾ à¤ªà¥‚à¤›à¤¨à¤¾ à¤šà¤¾à¤¹à¤¤à¥‡ à¤¹à¥ˆà¤‚? \n<end_of_turn>\nTOTAL TIME ELAPSED: 1.36s\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import keras\nimport keras_nlp\nimport datasets\n\n# Load a pre-trained Gemma tokenizer\n\ntokenizer = keras_nlp.models.GemmaTokenizer.from_preset(\"gemma2_instruct_2b_en\")\n\n## Load the Hindi-English translation dataset, this is they key to how good our model will work\nfrom datasets import load_dataset\nds = load_dataset(\n    \"/kaggle/input/iit-b-hindi/\",\n    split=\"train\",\n)\nprint(ds)\ndata = ds.with_format(\"np\", columns=[\"hindi\", \"english\"], output_all_columns=False)\ntrain = []\nfor x in data:\n  item = f\"<start_of_turn>user\\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾.\\n\\\"{x['hindi']}\\\"<end_of_turn>\\n<start_of_turn>model\\n{x['english']}<end_of_turn>\"\n  length = len(tokenizer(item))\n  # skip data if the token length is longer than our limit\n  if length < token_limit:\n    train.append(item)\n    if(len(train)>=num_data_limit):\n      break\n\n# Print the number of training examples and the first few examples\nprint(len(train))\nprint(train[0])\nprint(train[1])\nprint(train[2])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T03:44:58.679861Z","iopub.execute_input":"2025-02-19T03:44:58.680689Z","iopub.status.idle":"2025-02-19T03:45:13.860714Z","shell.execute_reply.started":"2025-02-19T03:44:58.68065Z","shell.execute_reply":"2025-02-19T03:45:13.859769Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4154ee4c485e42df8755ef9cb30a1a8c"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['hindi', 'english'],\n    num_rows: 1561841\n})\n100\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾.\n\"à¤…à¤ªà¤¨à¥‡ à¤…à¤¨à¥à¤ªà¥à¤°à¤¯à¥‹à¤— à¤•à¥‹ à¤ªà¤¹à¥à¤‚à¤šà¤¨à¥€à¤¯à¤¤à¤¾ à¤µà¥à¤¯à¤¾à¤¯à¤¾à¤® à¤•à¤¾ à¤²à¤¾à¤­ à¤¦à¥‡à¤‚\"<end_of_turn>\n<start_of_turn>model\nGive your application an accessibility workout<end_of_turn>\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾.\n\"à¤à¤•à¥à¤¸à¥‡à¤°à¥à¤¸à¤¾à¤‡à¤¸à¤° à¤ªà¤¹à¥à¤‚à¤šà¤¨à¥€à¤¯à¤¤à¤¾ à¤…à¤¨à¥à¤µà¥‡à¤·à¤•\"<end_of_turn>\n<start_of_turn>model\nAccerciser Accessibility Explorer<end_of_turn>\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾.\n\"à¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾\"<end_of_turn>\n<start_of_turn>model\nThe default plugin layout for the bottom panel<end_of_turn>\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Enable LoRA for the model and set the LoRA rank to 4.\ngemma_lm.backbone.enable_lora(rank=lora_rank)\n\n# Print a summary of the model, including LoRA parameters\ngemma_lm.summary()\n\n# Limit the input sequence length (to control memory usage).\ngemma_lm.preprocessor.sequence_length = token_limit\n\n# Configure the AdamW optimizer with weight decay\noptimizer = keras.optimizers.AdamW(\n    learning_rate=lr_value,\n    weight_decay=0.01,\n)\n# Exclude bias and scale parameters from weight decay\noptimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n\n# Compile the model with sparse categorical crossentropy loss and AdamW optimizer\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T03:45:28.886432Z","iopub.execute_input":"2025-02-19T03:45:28.887267Z","iopub.status.idle":"2025-02-19T03:45:29.090693Z","shell.execute_reply.started":"2025-02-19T03:45:28.887213Z","shell.execute_reply":"2025-02-19T03:45:29.089806Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              â”‚                      Vocab size: \u001b[38;5;34m256,000\u001b[0m â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)                                                  </span>â”ƒ<span style=\"font-weight: bold\">                                   Config </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              â”‚                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ gemma_backbone                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        â”‚   \u001b[38;5;34m2,617,270,528\u001b[0m â”‚ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        â”‚\nâ”‚ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               â”‚                           â”‚                 â”‚ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ token_embedding               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      â”‚     \u001b[38;5;34m589,824,000\u001b[0m â”‚ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”‚ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         â”‚                           â”‚                 â”‚                            â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)                  </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape              </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to               </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ gemma_backbone                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> â”‚ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               â”‚                           â”‚                 â”‚ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ token_embedding               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> â”‚ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         â”‚                           â”‚                 â”‚                            â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,617,270,528\u001b[0m (9.75 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> (9.75 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,928,640\u001b[0m (11.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,928,640</span> (11.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"### Custom callback for Keras that saves LoRA weights and performs basic evaluation after each training epoch.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nclass CustomCallback(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs=None):\n    model_name = f\"/kaggle/working/{lora_name}_{lora_rank}_epoch{epoch+1}.lora.h5\"\n    gemma_lm.backbone.save_lora_weights(model_name)\n\n    # Evaluate\n    text_gen(\"à¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾\")\n\n# Train the model with the custom callback\nhistory = gemma_lm.fit(train, epochs=train_epoch, batch_size=1, callbacks=[CustomCallback()])\n\n# Plot training history\n\nplt.plot(history.history['loss'])\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T03:45:46.059513Z","iopub.execute_input":"2025-02-19T03:45:46.060496Z","iopub.status.idle":"2025-02-19T04:01:38.332405Z","shell.execute_reply.started":"2025-02-19T03:45:46.060447Z","shell.execute_reply":"2025-02-19T04:01:38.331456Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1739936797.472002      91 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1739936818.062717      91 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_9', 436 bytes spill stores, 508 bytes spill loads\nptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 24 bytes spill stores, 24 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_7', 68 bytes spill stores, 116 bytes spill loads\nptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 12 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_5', 436 bytes spill stores, 508 bytes spill loads\nptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 24 bytes spill stores, 24 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - loss: 0.9846 - sparse_categorical_accuracy: 0.2871\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\n\"User\"<end_of_turn>\nTOTAL TIME ELAPSED: 22.97s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 657ms/step - loss: 0.9822 - sparse_categorical_accuracy: 0.2882\nEpoch 2/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.3413 - sparse_categorical_accuracy: 0.7511\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\n\"User\"<end_of_turn>\nTOTAL TIME ELAPSED: 0.35s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 428ms/step - loss: 0.3406 - sparse_categorical_accuracy: 0.7515\nEpoch 3/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.2536 - sparse_categorical_accuracy: 0.7970\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\n\"Type\"<end_of_turn>\nTOTAL TIME ELAPSED: 0.35s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 428ms/step - loss: 0.2532 - sparse_categorical_accuracy: 0.7973\nEpoch 4/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.2184 - sparse_categorical_accuracy: 0.8210\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\nThe _ _ _<end_of_turn>\nTOTAL TIME ELAPSED: 0.39s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 428ms/step - loss: 0.2180 - sparse_categorical_accuracy: 0.8212\nEpoch 5/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.1924 - sparse_categorical_accuracy: 0.8316\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\nThe _ _ _ of<end_of_turn>\nTOTAL TIME ELAPSED: 0.42s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 428ms/step - loss: 0.1921 - sparse_categorical_accuracy: 0.8318\nEpoch 6/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.1683 - sparse_categorical_accuracy: 0.8462\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\nThe _ \"___ \"<end_of_turn>\nTOTAL TIME ELAPSED: 0.42s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 428ms/step - loss: 0.1680 - sparse_categorical_accuracy: 0.8464\nEpoch 7/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.1444 - sparse_categorical_accuracy: 0.8657\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\nThe \" creÈ™t \"<end_of_turn>\nTOTAL TIME ELAPSED: 0.42s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 428ms/step - loss: 0.1442 - sparse_categorical_accuracy: 0.8659\nEpoch 8/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.1253 - sparse_categorical_accuracy: 0.8815\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\n\"Ñ… <start_of_turn>\nTOTAL TIME ELAPSED: 0.35s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 427ms/step - loss: 0.1251 - sparse_categorical_accuracy: 0.8816\nEpoch 9/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.1098 - sparse_categorical_accuracy: 0.8959\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\n\"The current settings of the plugin\"<end_of_turn>\nTOTAL TIME ELAPSED: 0.53s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 429ms/step - loss: 0.1096 - sparse_categorical_accuracy: 0.8960\nEpoch 10/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.0941 - sparse_categorical_accuracy: 0.9110\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\n viÃ±eta <end_of_turn>\nTOTAL TIME ELAPSED: 0.35s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 427ms/step - loss: 0.0940 - sparse_categorical_accuracy: 0.9110\nEpoch 11/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: 0.0817 - sparse_categorical_accuracy: 0.9215\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\n viÃ±eta<end_of_turn>\nTOTAL TIME ELAPSED: 0.32s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 426ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9214\nEpoch 12/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: 0.0734 - sparse_categorical_accuracy: 0.9284\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\n sienta<end_of_turn>\nTOTAL TIME ELAPSED: 0.28s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 426ms/step - loss: 0.0733 - sparse_categorical_accuracy: 0.9284\nEpoch 13/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9384\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\n sienta<end_of_turn>\nTOTAL TIME ELAPSED: 0.28s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 426ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9384\nEpoch 14/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: 0.0623 - sparse_categorical_accuracy: 0.9387\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\n smrti<end_of_turn>\nTOTAL TIME ELAPSED: 0.28s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 426ms/step - loss: 0.0623 - sparse_categorical_accuracy: 0.9387\nEpoch 15/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: 0.0564 - sparse_categorical_accuracy: 0.9397\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\n smrti<end_of_turn>\nTOTAL TIME ELAPSED: 0.28s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 426ms/step - loss: 0.0563 - sparse_categorical_accuracy: 0.9396\nEpoch 16/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.0519 - sparse_categorical_accuracy: 0.9418\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\n smrti<end_of_turn>\nTOTAL TIME ELAPSED: 0.29s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 427ms/step - loss: 0.0519 - sparse_categorical_accuracy: 0.9417\nEpoch 17/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.0490 - sparse_categorical_accuracy: 0.9419\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\nThe default plugin layout for the profile<end_of_turn>\nTOTAL TIME ELAPSED: 0.49s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 429ms/step - loss: 0.0490 - sparse_categorical_accuracy: 0.9418\nEpoch 18/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.0467 - sparse_categorical_accuracy: 0.9419\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\n viÃ±eta para el pin de entrada por defecto<end_of_turn>\nTOTAL TIME ELAPSED: 0.57s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 430ms/step - loss: 0.0467 - sparse_categorical_accuracy: 0.9418\nEpoch 19/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.0444 - sparse_categorical_accuracy: 0.9413\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\nThe default plugin layout for the panel<end_of_turn>\nTOTAL TIME ELAPSED: 0.49s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 429ms/step - loss: 0.0444 - sparse_categorical_accuracy: 0.9412\nEpoch 20/20\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.0425 - sparse_categorical_accuracy: 0.9425\nGemma output:\n<start_of_turn>user\nà¤¨à¤¿à¤šà¤²à¥‡ à¤ªà¤Ÿà¤² à¤•à¥‡ à¤²à¤¿à¤ à¤¡à¤¿à¤«à¥‹à¤²à¥à¤Ÿ à¤ªà¥à¤²à¤—-à¤‡à¤¨ à¤–à¤¾à¤•à¤¾<end_of_turn>\n<start_of_turn>model\n viÃ±eta para el pin de entrada por defecto<end_of_turn>\nTOTAL TIME ELAPSED: 0.57s\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 429ms/step - loss: 0.0425 - sparse_categorical_accuracy: 0.9424\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Example Code for Load LoRA\n\nimport os\nimport keras\nimport keras_nlp\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset('gemma2_instruct_2b_en')\n\n# Use the same LoRA rank that you trained, \n# https://keras.io/keras_hub/api/models/gemma/gemma_backbone/#gemmabackbone-class\ngemma_lm.backbone.enable_lora(rank=4)\n\n# Load pre-trained LoRA weights\ngemma_lm.backbone.load_lora_weights(f\"/kaggle/working/Roy_4_epoch20.lora.h5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Compile the model with a top-k and top-p sampling strategy and Generate text using the compiled model\n\n#### Influence of Parameter *k* on OutputThe parameter *k* directly controls the diversity of the generated text:\n\n\n* **Low *k*** (e.g., *k* = 1): With *k* = 1, top-k sampling behaves like greedy decoding, as only the most probable token is selected deterministically, resulting in a predictable and repetitive output.\n* **Moderate *k*** (e.g., *k* = 5â€“10): Small values of *k* introduce moderate randomness by restricting selection to the most probable tokens while maintaining context fidelity. This setting is useful when balanced diversity is desired, as it reduces the likelihood of incoherent or tangential token choices.\n* **High *k*** (e.g., *k* > 20): Larger values of *k* allow more diversity, as the model can choose from a broader set of tokens. However, this can also increase the risk of generating less coherent text, as the inclusion of lower-probability tokens may lead to irrelevant or unexpected output.The optimal value of *k* often depends on the specific task and the level of creativity or strictness required in the generated text.\n\n\nhttps://dataforest.ai/glossary/top-k-sampling#:~:text=However%2C%20this%20can%20also%20increase,lead%20to%20irrelevant%20or%20unexpected","metadata":{}},{"cell_type":"code","source":"gemma_lm.compile(sampler=\"top_k\") #default = 50\n\ntext_gen(\"à¤•à¥ƒà¤ªà¤¯à¤¾ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤²à¤¿à¤–à¥‡à¤‚:\\n\\\"à¤¹à¥ˆà¤²à¥‹, à¤®à¥ˆà¤‚ à¤¹à¤®à¤¾à¤°à¥€ à¤¶à¤¾à¤¦à¥€ à¤•à¥€ à¤¸à¤¾à¤²à¤—à¤¿à¤°à¤¹ à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤•à¥‡à¤• à¤¨à¤‚à¤¬à¤° 3 à¤‘à¤°à¥à¤¡à¤° à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¥‚à¤‚à¤—à¤¾?\")\ntext_gen(\"à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¨à¤¿à¤®à¥à¤¨à¤²à¤¿à¤–à¤¿à¤¤ à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤²à¤¿à¤–à¥‡à¤‚à¥¤\\n\\\"à¤¹à¥ˆà¤²à¥‹, à¤®à¥ˆà¤‚ à¤¹à¤®à¤¾à¤°à¥€ à¤¶à¤¾à¤¦à¥€ à¤•à¥€ à¤¸à¤¾à¤²à¤—à¤¿à¤°à¤¹ à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤•à¥‡à¤• à¤¨à¤‚à¤¬à¤° 3 à¤‘à¤°à¥à¤¡à¤° à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¥‚à¤‚à¤—à¤¾à¥¤ à¤•à¥à¤¯à¤¾ à¤¯à¤¹ à¤¸à¤‚à¤­à¤µ à¤¹à¥ˆ?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T04:01:45.494989Z","iopub.execute_input":"2025-02-19T04:01:45.495352Z","iopub.status.idle":"2025-02-19T04:02:17.094013Z","shell.execute_reply.started":"2025-02-19T04:01:45.495322Z","shell.execute_reply":"2025-02-19T04:02:17.093282Z"}},"outputs":[{"name":"stdout","text":"\nGemma output:\n<start_of_turn>user\nà¤•à¥ƒà¤ªà¤¯à¤¾ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤²à¤¿à¤–à¥‡à¤‚:\n\"à¤¹à¥ˆà¤²à¥‹, à¤®à¥ˆà¤‚ à¤¹à¤®à¤¾à¤°à¥€ à¤¶à¤¾à¤¦à¥€ à¤•à¥€ à¤¸à¤¾à¤²à¤—à¤¿à¤°à¤¹ à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤•à¥‡à¤• à¤¨à¤‚à¤¬à¤° 3 à¤‘à¤°à¥à¤¡à¤° à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¥‚à¤‚à¤—à¤¾?<end_of_turn>\n<start_of_turn>model\nHello! I would like to order a cake number 3 for your wedding anniversary.<end_of_turn>\nTOTAL TIME ELAPSED: 28.51s\n\nGemma output:\n<start_of_turn>user\nà¤•à¥ƒà¤ªà¤¯à¤¾ à¤¨à¤¿à¤®à¥à¤¨à¤²à¤¿à¤–à¤¿à¤¤ à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤²à¤¿à¤–à¥‡à¤‚à¥¤\n\"à¤¹à¥ˆà¤²à¥‹, à¤®à¥ˆà¤‚ à¤¹à¤®à¤¾à¤°à¥€ à¤¶à¤¾à¤¦à¥€ à¤•à¥€ à¤¸à¤¾à¤²à¤—à¤¿à¤°à¤¹ à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤•à¥‡à¤• à¤¨à¤‚à¤¬à¤° 3 à¤‘à¤°à¥à¤¡à¤° à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¥‚à¤‚à¤—à¤¾à¥¤ à¤•à¥à¤¯à¤¾ à¤¯à¤¹ à¤¸à¤‚à¤­à¤µ à¤¹à¥ˆ?<end_of_turn>\n<start_of_turn>model\nà¤¨à¤®à¤¸à¥à¤¤à¥‡!\n\nà¤†à¤œ à¤†à¤ª à¤…à¤ªà¤¨à¥€ à¤¶à¤¾à¤¦à¥€ à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤•à¥‡à¤• à¤•à¥€ à¤ªà¤‚à¤•à¥à¤¤à¤¿à¤¯à¥‹à¤‚ à¤•à¥‹ 3 à¤‘à¤°à¥à¤¡à¤° à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¤¤à¥‡ à¤¹à¥ˆà¤‚, à¤¤à¥‹ à¤¯à¤¹ à¤¸à¤‚à¤­à¤µ à¤¹à¥ˆà¥¤ ğŸ°ğŸ‰ \n\nà¤†à¤ªà¤•à¥‡ à¤ªà¤¸à¤‚à¤¦ à¤•à¥‡ à¤²à¤¿à¤ à¤µà¤¿à¤­à¤¿à¤¨à¥à¤¨ à¤ªà¥à¤°à¤•à¤¾à¤° à¤•à¥‡ à¤°à¤‚à¤—à¥‹à¤‚ à¤”à¤° à¤¸à¤œà¥à¤œà¤¨à¥‹à¤‚ à¤•à¥€ à¤ªà¤‚à¤•à¥à¤¤à¤¿à¤¯à¥‹à¤‚ à¤•à¥€ à¤ªà¤‚à¤•à¥à¤¤à¤¿à¤¯à¥‹à¤‚ à¤•à¥€ à¤ªà¤‚à¤•à¥à¤¤à¤¿à¤¯à¤¾à¤‚ à¤šà¥à¤¨à¥‡à¤‚à¥¤<end_of_turn>\nTOTAL TIME ELAPSED: 3.07s\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"gemma_lm.compile(sampler=\"top_k\") #default = 50\n\ntext_gen(\"à¤•à¥ƒà¤ªà¤¯à¤¾ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤²à¤¿à¤–à¥‡à¤‚:\\n\\\"à¤¹à¥ˆà¤²à¥‹, à¤®à¥ˆà¤‚ à¤¹à¤®à¤¾à¤°à¥€ à¤¶à¤¾à¤¦à¥€ à¤•à¥€ à¤¸à¤¾à¤²à¤—à¤¿à¤°à¤¹ à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤•à¥‡à¤• à¤¨à¤‚à¤¬à¤° 3 à¤‘à¤°à¥à¤¡à¤° à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¥‚à¤‚à¤—à¤¾?\")\ntext_gen(\"à¤•à¥ƒà¤ªà¤¯à¤¾ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤¸à¥‚à¤šà¥€ à¤•à¤¾ à¤…à¤¨à¥à¤¸à¤°à¤£ à¤•à¤°à¥‡à¤‚à¥¤ à¤”à¤° 10 à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¤¾à¤—à¤¤ à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤ªà¥‚à¤›à¥‡à¤‚\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T04:02:41.315981Z","iopub.execute_input":"2025-02-19T04:02:41.316461Z","iopub.status.idle":"2025-02-19T04:03:08.977878Z","shell.execute_reply.started":"2025-02-19T04:02:41.316418Z","shell.execute_reply":"2025-02-19T04:03:08.97702Z"}},"outputs":[{"name":"stdout","text":"\nGemma output:\n<start_of_turn>user\nà¤•à¥ƒà¤ªà¤¯à¤¾ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤²à¤¿à¤–à¥‡à¤‚:\n\"à¤¹à¥ˆà¤²à¥‹, à¤®à¥ˆà¤‚ à¤¹à¤®à¤¾à¤°à¥€ à¤¶à¤¾à¤¦à¥€ à¤•à¥€ à¤¸à¤¾à¤²à¤—à¤¿à¤°à¤¹ à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤•à¥‡à¤• à¤¨à¤‚à¤¬à¤° 3 à¤‘à¤°à¥à¤¡à¤° à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¥‚à¤‚à¤—à¤¾?<end_of_turn>\n<start_of_turn>model\nHello! I would like to order a cake number for the wedding anniversary.<end_of_turn>\nTOTAL TIME ELAPSED: 26.32s\n\nGemma output:\n<start_of_turn>user\nà¤•à¥ƒà¤ªà¤¯à¤¾ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤¸à¥‚à¤šà¥€ à¤•à¤¾ à¤…à¤¨à¥à¤¸à¤°à¤£ à¤•à¤°à¥‡à¤‚à¥¤ à¤”à¤° 10 à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¤¾à¤—à¤¤ à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤ªà¥‚à¤›à¥‡à¤‚<end_of_turn>\n<start_of_turn>model\nà¤µà¤¿à¤­à¤¿à¤¨à¥à¤¨ à¤‰à¤¤à¥à¤¤à¤°à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤–à¤¾à¤•à¤¾. à¤ªà¤‚à¤•à¥à¤¤à¤¿ à¤®à¥‡à¤‚ 10 à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¤¾à¤—à¤¤ à¤¨à¤¿à¤—à¤¾à¤¹ à¤®à¤¿à¤Ÿà¤¾à¤“.<end_of_turn>\nTOTAL TIME ELAPSED: 1.33s\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"\n\n\nhttps://docs.ai-solutions.ext.hpe.com/products/gen-ai/latest/get-started/glossary/model-params-top-p/#:~:text=Set%20a%20lower%20Top%2DP,to%20more%20likely%2C%20predictable%20words.","metadata":{}},{"cell_type":"code","source":"gemma_lm.compile(sampler=\"top_p\") #default=1\n\ntext_gen(\"à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¬à¥‡à¤•à¤° à¤•à¥‹ à¤ˆà¤®à¥‡à¤² à¤•à¤°à¥‡à¤‚ à¤”à¤° à¤¸à¥à¤¨à¤¿à¤¶à¥à¤šà¤¿à¤¤ à¤•à¤°à¥‡à¤‚ à¤•à¤¿ à¤µà¤¹ à¤¬à¥à¤²à¥ˆà¤• à¤«à¥‰à¤°à¥‡à¤¸à¥à¤Ÿ à¤•à¥‡à¤• à¤•à¥à¤¯à¤¾ à¤¬à¤¨à¤¾ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆ à¤”à¤° à¤¹à¤®à¤¾à¤°à¥€ à¤¶à¤¾à¤¦à¥€ à¤•à¥€ à¤¸à¤¾à¤²à¤—à¤¿à¤°à¤¹ à¤•à¥‡ à¤²à¤¿à¤ 4 à¤®à¥‹à¤®à¤¬à¤¤à¥à¤¤à¤¿à¤¯à¤¾à¤‚ à¤¦à¥‡ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆ à¤”à¤° à¤²à¤¾à¤—à¤¤\")\ntext_gen(\"à¤•à¥ƒà¤ªà¤¯à¤¾ à¤•à¥‡à¤• à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤¸à¥‚à¤šà¥€ à¤•à¤¾ à¤…à¤¨à¥à¤¸à¤°à¤£ à¤•à¤°à¥‡à¤‚ à¤”à¤° 10 à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¤¾à¤—à¤¤ à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤ªà¥‚à¤›à¥‡à¤‚\")\ntext_gen(\"à¤•à¥ƒà¤ªà¤¯à¤¾ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤²à¤¿à¤–à¥‡à¤‚:\\n\\\"à¤¹à¥ˆà¤²à¥‹, à¤®à¥ˆà¤‚ à¤¹à¤®à¤¾à¤°à¥€ à¤¶à¤¾à¤¦à¥€ à¤•à¥€ à¤¸à¤¾à¤²à¤—à¤¿à¤°à¤¹ à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤•à¥‡à¤• à¤¨à¤‚à¤¬à¤° 3 à¤‘à¤°à¥à¤¡à¤° à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¥‚à¤‚à¤—à¤¾?\")\ntext_gen(\"à¤•à¥ƒà¤ªà¤¯à¤¾ à¤•à¥‡à¤• à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤¸à¥‚à¤šà¥€ à¤•à¤¾ à¤…à¤¨à¥à¤¸à¤°à¤£ à¤•à¤°à¥‡à¤‚ à¤”à¤° 10 à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¤¾à¤—à¤¤ à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤ªà¥‚à¤›à¥‡à¤‚, à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¬à¤¾à¤‚à¤—à¥à¤²à¤¾ à¤®à¥‡à¤‚ à¤ªà¥à¤°à¤¤à¤¿à¤•à¥à¤°à¤¿à¤¯à¤¾ à¤•à¥‡ à¤²à¤¿à¤ à¤ªà¥‚à¤›à¥‡à¤‚à¥¤\")\ntext_gen(\"à¤•à¥ƒà¤ªà¤¯à¤¾ à¤•à¥‡à¤• à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤¸à¥‚à¤šà¥€ à¤•à¤¾ à¤…à¤¨à¥à¤¸à¤°à¤£ à¤•à¤°à¥‡à¤‚ à¤”à¤° 10 à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¤¾à¤—à¤¤ à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤ªà¥‚à¤›à¥‡à¤‚, à¤•à¥ƒà¤ªà¤¯à¤¾ à¤…à¤‚à¤—à¥à¤°à¥‡à¤œà¥€ à¤®à¥‡à¤‚ à¤ªà¥à¤°à¤¤à¤¿à¤•à¥à¤°à¤¿à¤¯à¤¾ à¤®à¤¾à¤‚à¤—à¥‡à¤‚\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T04:04:48.087833Z","iopub.execute_input":"2025-02-19T04:04:48.088248Z","iopub.status.idle":"2025-02-19T04:06:38.406616Z","shell.execute_reply.started":"2025-02-19T04:04:48.088201Z","shell.execute_reply":"2025-02-19T04:06:38.405593Z"}},"outputs":[{"name":"stdout","text":"\nGemma output:\n<start_of_turn>user\nà¤•à¥ƒà¤ªà¤¯à¤¾ à¤¬à¥‡à¤•à¤° à¤•à¥‹ à¤ˆà¤®à¥‡à¤² à¤•à¤°à¥‡à¤‚ à¤”à¤° à¤¸à¥à¤¨à¤¿à¤¶à¥à¤šà¤¿à¤¤ à¤•à¤°à¥‡à¤‚ à¤•à¤¿ à¤µà¤¹ à¤¬à¥à¤²à¥ˆà¤• à¤«à¥‰à¤°à¥‡à¤¸à¥à¤Ÿ à¤•à¥‡à¤• à¤•à¥à¤¯à¤¾ à¤¬à¤¨à¤¾ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆ à¤”à¤° à¤¹à¤®à¤¾à¤°à¥€ à¤¶à¤¾à¤¦à¥€ à¤•à¥€ à¤¸à¤¾à¤²à¤—à¤¿à¤°à¤¹ à¤•à¥‡ à¤²à¤¿à¤ 4 à¤®à¥‹à¤®à¤¬à¤¤à¥à¤¤à¤¿à¤¯à¤¾à¤‚ à¤¦à¥‡ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆ à¤”à¤° à¤²à¤¾à¤—à¤¤<end_of_turn>\n<start_of_turn>model\nSubject: Cake order for wedding anniversary\n\nGood morning/afternoon, [Baker's name]\n\nI hope this email finds you well.\n\nWe'd like to place an order for a cake for our wedding anniversary, which falls on [Date]. \n\nCould you please tell us what flavours you offer for the Black Forest cake and what the cost would be? We would also appreciate it if you could confirm how many candles you can provide for the cake.\n\nThank you for your time and we look forward to hearing from you soon.\n\nBest regards,\n[Your name]<end_of_turn>\nTOTAL TIME ELAPSED: 51.09s\n\nGemma output:\n<start_of_turn>user\nà¤•à¥ƒà¤ªà¤¯à¤¾ à¤•à¥‡à¤• à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤¸à¥‚à¤šà¥€ à¤•à¤¾ à¤…à¤¨à¥à¤¸à¤°à¤£ à¤•à¤°à¥‡à¤‚ à¤”à¤° 10 à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¤¾à¤—à¤¤ à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤ªà¥‚à¤›à¥‡à¤‚<end_of_turn>\n<start_of_turn>model\nà¤µà¤¿à¤­à¤¾à¤— à¤•à¥‡ à¤²à¤¿à¤ à¤†à¤¯à¥‹à¤œà¤¨à¤¾à¤• à¤ªà¤Ÿà¤²à¤§à¤¾à¤®à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§à¥à¤‚à¤§à¤•à¤§\nTOTAL TIME ELAPSED: 41.51s\n\nGemma output:\n<start_of_turn>user\nà¤•à¥ƒà¤ªà¤¯à¤¾ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤²à¤¿à¤–à¥‡à¤‚:\n\"à¤¹à¥ˆà¤²à¥‹, à¤®à¥ˆà¤‚ à¤¹à¤®à¤¾à¤°à¥€ à¤¶à¤¾à¤¦à¥€ à¤•à¥€ à¤¸à¤¾à¤²à¤—à¤¿à¤°à¤¹ à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤•à¥‡à¤• à¤¨à¤‚à¤¬à¤° 3 à¤‘à¤°à¥à¤¡à¤° à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¥‚à¤‚à¤—à¤¾?<end_of_turn>\n<start_of_turn>model\nHello! I would like to order a cake for the anniversary of your wedding. How many numbers would you like?<end_of_turn>\nTOTAL TIME ELAPSED: 5.00s\n\nGemma output:\n<start_of_turn>user\nà¤•à¥ƒà¤ªà¤¯à¤¾ à¤•à¥‡à¤• à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤¸à¥‚à¤šà¥€ à¤•à¤¾ à¤…à¤¨à¥à¤¸à¤°à¤£ à¤•à¤°à¥‡à¤‚ à¤”à¤° 10 à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¤¾à¤—à¤¤ à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤ªà¥‚à¤›à¥‡à¤‚, à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¬à¤¾à¤‚à¤—à¥à¤²à¤¾ à¤®à¥‡à¤‚ à¤ªà¥à¤°à¤¤à¤¿à¤•à¥à¤°à¤¿à¤¯à¤¾ à¤•à¥‡ à¤²à¤¿à¤ à¤ªà¥‚à¤›à¥‡à¤‚à¥¤<end_of_turn>\n<start_of_turn>model\nà¤¨à¤®à¤¸à¥à¤¤à¥‡! 10 ngÆ°á»i à¤•à¥‡ à¤²à¤¿à¤ à¤•à¥‡à¤• à¤•à¥€ à¤²à¤¾à¤—à¤¤ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤ªà¥à¤°à¤¾à¤ªà¥à¤¤ à¤•à¤°à¥‡à¤‚, Por favor, à¤‰à¤¤à¥à¤¤à¤° à¤•à¥‡ à¤²à¤¿à¤ à¦¬à¦¾à¦‚à¦²à¦¾ à¤­à¤¾à¤·à¤¾ à¤®à¥‡à¤‚ à¤ªà¥à¤°à¤¤à¤¿à¤•à¥à¤°à¤¿à¤¯à¤¾ à¤¦à¥‡à¤‚à¥¤ \n<end_of_turn>\nTOTAL TIME ELAPSED: 8.48s\n\nGemma output:\n<start_of_turn>user\nà¤•à¥ƒà¤ªà¤¯à¤¾ à¤•à¥‡à¤• à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤¸à¥‚à¤šà¥€ à¤•à¤¾ à¤…à¤¨à¥à¤¸à¤°à¤£ à¤•à¤°à¥‡à¤‚ à¤”à¤° 10 à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¤¾à¤—à¤¤ à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤ªà¥‚à¤›à¥‡à¤‚, à¤•à¥ƒà¤ªà¤¯à¤¾ à¤…à¤‚à¤—à¥à¤°à¥‡à¤œà¥€ à¤®à¥‡à¤‚ à¤ªà¥à¤°à¤¤à¤¿à¤•à¥à¤°à¤¿à¤¯à¤¾ à¤®à¤¾à¤‚à¤—à¥‡à¤‚<end_of_turn>\n<start_of_turn>model\nà¤¨à¤®à¤¸à¥à¤¤à¥‡! Please provide the cost estimation for 10 people's cake.<end_of_turn>\nTOTAL TIME ELAPSED: 4.22s\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"gemma_lm.compile(sampler=\"top_k\") #default=1\n\ntext_gen(\"à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¬à¥‡à¤•à¤° à¤•à¥‹ à¤ˆà¤®à¥‡à¤² à¤•à¤°à¥‡à¤‚ à¤”à¤° à¤¸à¥à¤¨à¤¿à¤¶à¥à¤šà¤¿à¤¤ à¤•à¤°à¥‡à¤‚ à¤•à¤¿ à¤µà¤¹ à¤¬à¥à¤²à¥ˆà¤• à¤«à¥‰à¤°à¥‡à¤¸à¥à¤Ÿ à¤•à¥‡à¤• à¤•à¥à¤¯à¤¾ à¤¬à¤¨à¤¾ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆ à¤”à¤° à¤¹à¤®à¤¾à¤°à¥€ à¤¶à¤¾à¤¦à¥€ à¤•à¥€ à¤¸à¤¾à¤²à¤—à¤¿à¤°à¤¹ à¤•à¥‡ à¤²à¤¿à¤ 4 à¤®à¥‹à¤®à¤¬à¤¤à¥à¤¤à¤¿à¤¯à¤¾à¤‚ à¤¦à¥‡ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆ à¤”à¤° à¤²à¤¾à¤—à¤¤\")\ntext_gen(\"à¤•à¥ƒà¤ªà¤¯à¤¾ à¤•à¥‡à¤• à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤¸à¥‚à¤šà¥€ à¤•à¤¾ à¤…à¤¨à¥à¤¸à¤°à¤£ à¤•à¤°à¥‡à¤‚ à¤”à¤° 10 à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¤¾à¤—à¤¤ à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤ªà¥‚à¤›à¥‡à¤‚\")\ntext_gen(\"à¤•à¥ƒà¤ªà¤¯à¤¾ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤²à¤¿à¤–à¥‡à¤‚:\\n\\\"à¤¹à¥ˆà¤²à¥‹, à¤®à¥ˆà¤‚ à¤¹à¤®à¤¾à¤°à¥€ à¤¶à¤¾à¤¦à¥€ à¤•à¥€ à¤¸à¤¾à¤²à¤—à¤¿à¤°à¤¹ à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤•à¥‡à¤• à¤¨à¤‚à¤¬à¤° 3 à¤‘à¤°à¥à¤¡à¤° à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¥‚à¤‚à¤—à¤¾?\")\ntext_gen(\"à¤•à¥ƒà¤ªà¤¯à¤¾ à¤•à¥‡à¤• à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤¸à¥‚à¤šà¥€ à¤•à¤¾ à¤…à¤¨à¥à¤¸à¤°à¤£ à¤•à¤°à¥‡à¤‚ à¤”à¤° 10 à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¤¾à¤—à¤¤ à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤ªà¥‚à¤›à¥‡à¤‚, à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¬à¤¾à¤‚à¤—à¥à¤²à¤¾ à¤®à¥‡à¤‚ à¤ªà¥à¤°à¤¤à¤¿à¤•à¥à¤°à¤¿à¤¯à¤¾ à¤•à¥‡ à¤²à¤¿à¤ à¤ªà¥‚à¤›à¥‡à¤‚à¥¤\")\ntext_gen(\"à¤•à¥ƒà¤ªà¤¯à¤¾ à¤•à¥‡à¤• à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤¸à¥‚à¤šà¥€ à¤•à¤¾ à¤…à¤¨à¥à¤¸à¤°à¤£ à¤•à¤°à¥‡à¤‚ à¤”à¤° 10 à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¤¾à¤—à¤¤ à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤ªà¥‚à¤›à¥‡à¤‚, à¤•à¥ƒà¤ªà¤¯à¤¾ à¤…à¤‚à¤—à¥à¤°à¥‡à¤œà¥€ à¤®à¥‡à¤‚ à¤ªà¥à¤°à¤¤à¤¿à¤•à¥à¤°à¤¿à¤¯à¤¾ à¤®à¤¾à¤‚à¤—à¥‡à¤‚\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T04:07:52.95666Z","iopub.execute_input":"2025-02-19T04:07:52.957026Z","iopub.status.idle":"2025-02-19T04:08:31.800499Z","shell.execute_reply.started":"2025-02-19T04:07:52.956992Z","shell.execute_reply":"2025-02-19T04:08:31.799331Z"}},"outputs":[{"name":"stdout","text":"\nGemma output:\n<start_of_turn>user\nà¤•à¥ƒà¤ªà¤¯à¤¾ à¤¬à¥‡à¤•à¤° à¤•à¥‹ à¤ˆà¤®à¥‡à¤² à¤•à¤°à¥‡à¤‚ à¤”à¤° à¤¸à¥à¤¨à¤¿à¤¶à¥à¤šà¤¿à¤¤ à¤•à¤°à¥‡à¤‚ à¤•à¤¿ à¤µà¤¹ à¤¬à¥à¤²à¥ˆà¤• à¤«à¥‰à¤°à¥‡à¤¸à¥à¤Ÿ à¤•à¥‡à¤• à¤•à¥à¤¯à¤¾ à¤¬à¤¨à¤¾ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆ à¤”à¤° à¤¹à¤®à¤¾à¤°à¥€ à¤¶à¤¾à¤¦à¥€ à¤•à¥€ à¤¸à¤¾à¤²à¤—à¤¿à¤°à¤¹ à¤•à¥‡ à¤²à¤¿à¤ 4 à¤®à¥‹à¤®à¤¬à¤¤à¥à¤¤à¤¿à¤¯à¤¾à¤‚ à¤¦à¥‡ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆ à¤”à¤° à¤²à¤¾à¤—à¤¤<end_of_turn>\n<start_of_turn>model\nSubject: Chocolate Forest Cake Order - Anniversary Celebration\n\nGood morning, Baker!\n\nWe'd like to place an order for a chocolate forest cake for our anniversary celebration. Please let us know what flavours and fillings your bakery offers for this type of cake.\n\nIdeally, we would like a four-tier cake decorated to resemble a forest with moss, trees, and edible animals. Please confirm the availability of this design and the approximate cost.\n\nThank you for your time and we look forward to hearing from you soon!\n\nBest regards,\n\n[Your Name]<end_of_turn>\nTOTAL TIME ELAPSED: 32.21s\n\nGemma output:\n<start_of_turn>user\nà¤•à¥ƒà¤ªà¤¯à¤¾ à¤•à¥‡à¤• à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤¸à¥‚à¤šà¥€ à¤•à¤¾ à¤…à¤¨à¥à¤¸à¤°à¤£ à¤•à¤°à¥‡à¤‚ à¤”à¤° 10 à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¤¾à¤—à¤¤ à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤ªà¥‚à¤›à¥‡à¤‚<end_of_turn>\n<start_of_turn>model\nà¤µà¤¿à¤­à¤¾à¤— à¤•à¥‡ à¤²à¤¿à¤ à¤†à¤¯à¥‹à¤œà¤¨à¤¾ à¤•à¥‹ 10 à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¤¾à¤—à¤¤à¥‹à¤‚ à¤•à¥‹ à¤–à¤¾à¤•à¤¾à¤ à¤¦à¥‡à¤‚à¥¤ \n\n1. à¤à¤• à¤¨à¥‹à¤Ÿ à¤•à¥‹ à¤–à¤¾à¤•à¤¾à¤à¥¤\n2. à¤•à¥à¤² à¤²à¤¾à¤—à¤¤à¥¤\n3. à¤ªà¤‚à¤•à¥à¤¤à¤¿ à¤®à¥‡à¤‚ à¤²à¤¾à¤—à¤¤à¥¤\n4. à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤—à¤¤ à¤²à¤¾à¤—à¤¤ à¤•à¥‹ à¤¶à¤¾à¤®à¤¿à¤² à¤•à¤°à¥‡à¤‚à¥¤\n5. à¤²à¤¾à¤—à¤¤ à¤•à¥‹ à¤¶à¤¾à¤®à¤¿à¤² à¤•à¤°à¥‡à¤‚à¥¤<end_of_turn>\nTOTAL TIME ELAPSED: 2.85s\n\nGemma output:\n<start_of_turn>user\nà¤•à¥ƒà¤ªà¤¯à¤¾ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤²à¤¿à¤–à¥‡à¤‚:\n\"à¤¹à¥ˆà¤²à¥‹, à¤®à¥ˆà¤‚ à¤¹à¤®à¤¾à¤°à¥€ à¤¶à¤¾à¤¦à¥€ à¤•à¥€ à¤¸à¤¾à¤²à¤—à¤¿à¤°à¤¹ à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤•à¥‡à¤• à¤¨à¤‚à¤¬à¤° 3 à¤‘à¤°à¥à¤¡à¤° à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¥‚à¤‚à¤—à¤¾?<end_of_turn>\n<start_of_turn>model\nà¤¨à¤®à¤¸à¥à¤¤à¥‡!  à¤†à¤ªà¤•à¥‡ à¤¶à¤¾à¤¦à¥€ à¤•à¥€ à¤¸à¤¾à¤²à¤—à¤¿à¤°à¤¹ à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤•à¥‡à¤• à¤¨à¤‚à¤¬à¤° 3 à¤‘à¤°à¥à¤¡à¤° à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¤¤à¥‡ à¤¹à¥ˆà¤‚? sieurs.<end_of_turn>\nTOTAL TIME ELAPSED: 1.47s\n\nGemma output:\n<start_of_turn>user\nà¤•à¥ƒà¤ªà¤¯à¤¾ à¤•à¥‡à¤• à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤¸à¥‚à¤šà¥€ à¤•à¤¾ à¤…à¤¨à¥à¤¸à¤°à¤£ à¤•à¤°à¥‡à¤‚ à¤”à¤° 10 à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¤¾à¤—à¤¤ à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤ªà¥‚à¤›à¥‡à¤‚, à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¬à¤¾à¤‚à¤—à¥à¤²à¤¾ à¤®à¥‡à¤‚ à¤ªà¥à¤°à¤¤à¤¿à¤•à¥à¤°à¤¿à¤¯à¤¾ à¤•à¥‡ à¤²à¤¿à¤ à¤ªà¥‚à¤›à¥‡à¤‚à¥¤<end_of_turn>\n<start_of_turn>model\nà¦¸à¦¾à¦¬à¦ªà¦¾à¦¤à¦•, 10 à¦œà¦¨à§‡à¦° à¦œà¦¨à§à¦¯ à¦ªà§à¦¯à¦¾à¦•à§‡à¦œà§‡à¦° à¤²à¤¾à¤—à¤¤à§‡à¦° à¦¤à¦¥à§à¦¯ à¦œà¦¿à¦œà§à¦à¦¾à¦¸à¦¾ à¦•à¦°à§à¦¨à¥¤ \n<end_of_turn>\nTOTAL TIME ELAPSED: 1.47s\n\nGemma output:\n<start_of_turn>user\nà¤•à¥ƒà¤ªà¤¯à¤¾ à¤•à¥‡à¤• à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤ˆà¤®à¥‡à¤² à¤‰à¤¤à¥à¤¤à¤° à¤¸à¥‚à¤šà¥€ à¤•à¤¾ à¤…à¤¨à¥à¤¸à¤°à¤£ à¤•à¤°à¥‡à¤‚ à¤”à¤° 10 à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¤¾à¤—à¤¤ à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤ªà¥‚à¤›à¥‡à¤‚, à¤•à¥ƒà¤ªà¤¯à¤¾ à¤…à¤‚à¤—à¥à¤°à¥‡à¤œà¥€ à¤®à¥‡à¤‚ à¤ªà¥à¤°à¤¤à¤¿à¤•à¥à¤°à¤¿à¤¯à¤¾ à¤®à¤¾à¤‚à¤—à¥‡à¤‚<end_of_turn>\n<start_of_turn>model\nà¤¨à¤®à¤¸à¥à¤¤à¥‡! Please provide the cost estimation for 10 people.<end_of_turn>\nTOTAL TIME ELAPSED: 0.82s\n","output_type":"stream"}],"execution_count":8}]}