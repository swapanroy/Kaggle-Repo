{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":7639866,"datasetId":841565,"databundleVersionId":7736362},{"sourceType":"modelInstanceVersion","sourceId":85986,"databundleVersionId":9247152,"modelInstanceId":72246},{"sourceType":"modelInstanceVersion","sourceId":205096,"databundleVersionId":10555752,"modelInstanceId":72246}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" # Medical domain adaptation using Gemma 2","metadata":{}},{"cell_type":"markdown","source":"# Install dependencies","metadata":{}},{"cell_type":"code","source":"!pip install -q -U keras-core\n!pip install -q -U keras-nlp\n!pip install -q -U keras==3.5.0  # Use Keras 3.x to work with JAX\n!pip install -q -U kagglehub \n!pip install -q -U tensorflow==2.17.0\n!pip install -q -U rouge-score\n!pip install -q -U jax\n!pip install -q -U jaxlib --upgrade \nprint(\"Installation Complete\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-28T21:30:01.414704Z","iopub.execute_input":"2025-02-28T21:30:01.415132Z","iopub.status.idle":"2025-02-28T21:32:15.908765Z","shell.execute_reply.started":"2025-02-28T21:30:01.415101Z","shell.execute_reply":"2025-02-28T21:32:15.906974Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.8/704.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstallation Complete\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport os\nimport keras_nlp\nimport keras\nimport tensorflow as tf\nimport json\nimport requests\nfrom IPython.display import clear_output\n\n# Make sure we're using JAX backend for Keras\nkeras.config.set_backend(\"jax\")\n\nprint(\"Keras backend:\", keras.backend.backend()) #Verify the backend\nprint(\"Tenserflow version:\", tf.__version__) #Verify the backend\n\n# Load Kaggle secrets for Gemini API key\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n\n\n# Load the clinical QnA dataset\n# Data is in a CSV file named 'medquad.csv'\n\n# Load the clinical QnA dataset\ntry:\n    df = pd.read_csv('medquad.csv.csv')\n    print(f\"Dataset loaded with {len(df)} rows\")\n    print(\"Sample data:\")\n    print(df.head(2))\nexcept Exception as e:\n    print(f\"Error loading dataset: {e}\")\n    print(\"Creating empty dataframe for demo purposes\")\n    df = pd.DataFrame(columns=['questions', 'answers', 'source', 'focus_areas'])\n\ndf = pd.read_csv('/kaggle/input/layoutlm/medquad.csv')\n\n# Display dataset info\nprint(f\"Dataset loaded with {len(df)} rows\")\nprint(\"Sample data:\")\nprint(df.head(2))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T21:33:18.830781Z","iopub.execute_input":"2025-02-28T21:33:18.831092Z","iopub.status.idle":"2025-02-28T21:33:19.855205Z","shell.execute_reply.started":"2025-02-28T21:33:18.831059Z","shell.execute_reply":"2025-02-28T21:33:19.854129Z"}},"outputs":[{"name":"stdout","text":"Keras backend: tensorflow\nTenserflow version: 2.17.1\nError loading dataset: [Errno 2] No such file or directory: 'medquad.csv.csv'\nCreating empty dataframe for demo purposes\nDataset loaded with 16412 rows\nSample data:\n                   question  \\\n0  What is (are) Glaucoma ?   \n1    What causes Glaucoma ?   \n\n                                              answer           source  \\\n0  Glaucoma is a group of diseases that can damag...  NIHSeniorHealth   \n1  Nearly 2.7 million people have glaucoma, a lea...  NIHSeniorHealth   \n\n  focus_area  \n0   Glaucoma  \n1   Glaucoma  \n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Load your Keras model","metadata":{}},{"cell_type":"code","source":"import keras_nlp \n\n# Load your Keras model\n\ngemma_lm = keras_nlp .models.GemmaCausalLM.from_preset('gemma2_instruct_2b_en')\n\n# Initialize the Gemma model with Keras\n#gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset('gemma2_instruct_2b_en')\n\n# Print a summary of the model's architecture\nprint(\"Model loaded successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T21:33:27.474701Z","iopub.execute_input":"2025-02-28T21:33:27.475050Z","iopub.status.idle":"2025-02-28T21:34:52.003045Z","shell.execute_reply.started":"2025-02-28T21:33:27.475023Z","shell.execute_reply":"2025-02-28T21:34:52.002089Z"}},"outputs":[{"name":"stdout","text":"Model loaded successfully\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Print a summary of the model's architecture\ngemma_lm.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T21:35:38.130074Z","iopub.execute_input":"2025-02-28T21:35:38.130453Z","iopub.status.idle":"2025-02-28T21:35:38.159382Z","shell.execute_reply.started":"2025-02-28T21:35:38.130422Z","shell.execute_reply":"2025-02-28T21:35:38.158533Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,614,341,888\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## Functions to start, stop and print the timer","metadata":{}},{"cell_type":"code","source":"token_limit = 254\n\n# Initialize a variable to track the start time\ntick_start = 0\n\n# Functions to start, stop and print the timer\ndef tick():\n    global tick_start\n    tick_start = time.time()\n\ndef tock():\n    print(f\"TOTAL TIME ELAPSED: {time.time() - tick_start:.2f}s\")\n\ndef text_gen(prompt):\n    \"\"\"Generate text using Gemma model\"\"\"\n    tick()\n    input = f\"<start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n    output = gemma_lm.generate(input, max_length=token_limit)\n    print(\"\\nGemma output:\")\n    print(output)\n    tock()\n    return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T21:56:11.247696Z","iopub.execute_input":"2025-02-28T21:56:11.248942Z","iopub.status.idle":"2025-02-28T21:56:11.259200Z","shell.execute_reply.started":"2025-02-28T21:56:11.248799Z","shell.execute_reply":"2025-02-28T21:56:11.257658Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Function to generate QnA prompt from dataset","metadata":{}},{"cell_type":"code","source":"# Function to generate QnA prompt from dataset\ndef create_qna_prompt(question, focus_area=None):\n    \"\"\"Create a prompt for the model based on the question and focus area\"\"\"\n    if focus_area:\n        prompt = f\"\"\"You are a medical expert specializing in {focus_area}.\nPlease answer the following medical question accurately and thoroughly.\nInclude the focus area and any relevant sources in your answer:\n\nQuestion: {question}\"\"\"\n    else:\n        prompt = f\"\"\"You are a medical expert.\nPlease answer the following medical question accurately and thoroughly.\nInclude the relevant medical focus area and any sources in your answer:\n\nQuestion: {question}\"\"\"\n    return prompt\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T21:56:14.065380Z","iopub.execute_input":"2025-02-28T21:56:14.065758Z","iopub.status.idle":"2025-02-28T21:56:14.070631Z","shell.execute_reply.started":"2025-02-28T21:56:14.065705Z","shell.execute_reply":"2025-02-28T21:56:14.069500Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Function to evaluate model responses against ground truth and handle medical questions","metadata":{}},{"cell_type":"code","source":"# Function to evaluate model responses against ground truth\ndef evaluate_response(model_answer, ground_truth):\n    \"\"\"Simple evaluation of model answer against ground truth\"\"\"\n    # This is a placeholder - in production you'd use metrics like ROUGE, BLEU, etc.\n    # For now, we'll just check if keywords from ground truth are in the model answer\n    ground_truth_words = set(ground_truth.lower().split())\n    model_answer_words = set(model_answer.lower().split())\n    common_words = ground_truth_words.intersection(model_answer_words)\n    \n    coverage = len(common_words) / len(ground_truth_words) if ground_truth_words else 0\n    return {\n        \"keyword_coverage\": coverage,\n        \"common_keywords\": list(common_words)[:10]  # Show first 10 common words\n    }\n\n# Function to handle user medical questions\ndef ask_medical_question():\n    question = input(\"\\nEnter your medical question: \")\n    if not question.strip():\n        print(\"Question cannot be empty.\")\n        return\n        \n    focus_area = input(\"Enter a specific medical focus area (optional, press Enter to skip): \")\n    if not focus_area.strip():\n        focus_area = None\n        \n    print(f\"\\nProcessing question: {question}\")\n    prompt = create_qna_prompt(question, focus_area)\n    response = text_gen(prompt)\n    \n    print(\"\\n=== Final Answer ===\")\n    print(response)\n    \n    # Save this interaction\n    with open('medical_qa_history.txt', 'a') as f:\n        f.write(f\"Question: {question}\\n\")\n        f.write(f\"Focus Area: {focus_area if focus_area else 'Not specified'}\\n\")\n        f.write(f\"Answer: {response}\\n\\n\")\n        f.write(\"-\" * 80 + \"\\n\\n\")\n    \n    print(\"\\nThis interaction has been saved to 'medical_qa_history.txt'\")\n\n# Create a demonstration pipeline (In progress)\ndef run_qna_pipeline(num_samples=5):\n    \"\"\"Run the QnA pipeline on a subset of the dataset\"\"\"\n    # Get a sample of questions to process\n    if len(df) > num_samples:\n        sample_df = df.sample(num_samples)\n    else:\n        sample_df = df\n    \n    results = []\n    \n    for idx, row in sample_df.iterrows():\n        question = row['questions']\n        ground_truth = row['answers']\n        focus_area = row['focus_areas'] if 'focus_areas' in row else None\n        \n        print(f\"\\n{'='*80}\")\n        print(f\"SAMPLE {idx+1}: {question}\")\n        print(f\"Focus Area: {focus_area}\")\n        \n        # Create prompt and generate response\n        prompt = create_qna_prompt(question, focus_area)\n        model_response = text_gen(prompt)\n        \n        # Evaluate the response\n        evaluation = evaluate_response(model_response, ground_truth)\n        \n        # Store results\n        results.append({\n            'question': question,\n            'ground_truth': ground_truth,\n            'model_response': model_response,\n            'focus_area': focus_area,\n            'evaluation': evaluation\n        })\n        \n    return results\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T21:56:21.694459Z","iopub.execute_input":"2025-02-28T21:56:21.694836Z","iopub.status.idle":"2025-02-28T21:56:21.705065Z","shell.execute_reply.started":"2025-02-28T21:56:21.694804Z","shell.execute_reply":"2025-02-28T21:56:21.704076Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Main menu with prompt options","metadata":{}},{"cell_type":"code","source":"# Main menu function\ndef display_menu():\n    print(\"\\n\" + \"=\"*50)\n    print(\"MEDICAL Q&A ASSISTANT\")\n    print(\"=\"*50)\n    print(\"1. Ask a medical question\")\n    print(\"2. Run demonstration pipeline (with example data)\")\n    print(\"3. Quit\")\n    \n    while True:\n        try:\n            choice = input(\"\\nEnter your choice (1-3): \")\n            if choice == '1':\n                ask_medical_question()\n                return True\n            elif choice == '2':\n                print(\"\\nStarting Clinical QnA Pipeline...\")\n                results = run_qna_pipeline(2)\n                \n                # Summary of results\n                print(\"\\n\\nSUMMARY OF RESULTS:\")\n                for i, result in enumerate(results):\n                    print(f\"\\n{i+1}. Question: {result['question']}\")\n                    print(f\"   Keyword Coverage: {result['evaluation']['keyword_coverage']:.2f}\")\n                \n                # Save results to CSV\n                results_df = pd.DataFrame([{\n                    'question': r['question'], \n                    'ground_truth': r['ground_truth'], \n                    'model_response': r['model_response'],\n                    'focus_area': r['focus_area'],\n                    'keyword_coverage': r['evaluation']['keyword_coverage']\n                } for r in results])\n                \n                results_df.to_csv('gemini_clinical_qna_results.csv', index=False)\n                print(\"\\nResults saved to 'gemini_clinical_qna_results.csv'\")\n                return True\n            elif choice == '3':\n                print(\"\\nExiting program. Thank you for using the Medical Q&A Assistant!\")\n                return False\n            else:\n                print(\"Invalid choice. Please enter 1, 2, or 3.\")\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            print(\"Please try again.\")\n\n# Main program loop\ndef main():\n    print(\"\\nInitializing Medical Q&A System...\")\n    \n    # Create history file if it doesn't exist\n    if not os.path.exists('medical_qa_history.txt'):\n        with open('medical_qa_history.txt', 'w') as f:\n            f.write(\"MEDICAL Q&A HISTORY\\n\")\n            f.write(\"=\" * 80 + \"\\n\\n\")\n    \n    continue_program = True\n    while continue_program:\n        continue_program = display_menu()\n    \n    print(\"Program terminated.\")\n\n# Run the main program\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T22:23:10.908526Z","iopub.execute_input":"2025-02-28T22:23:10.910077Z","execution_failed":"2025-03-01T01:02:11.891Z"}},"outputs":[{"name":"stdout","text":"\nInitializing Medical Q&A System...\n\n==================================================\nMEDICAL Q&A ASSISTANT\n==================================================\n1. Ask a medical question\n2. Run demonstration pipeline (with example data)\n3. Quit\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter your choice (1-3):  2\n"},{"name":"stdout","text":"\nStarting Clinical QnA Pipeline...\nAn error occurred: 'questions'\nPlease try again.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter your choice (1-3):  2\n"},{"name":"stdout","text":"\nStarting Clinical QnA Pipeline...\nAn error occurred: 'questions'\nPlease try again.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter your choice (1-3):  What is Downsyndrome ?\n"},{"name":"stdout","text":"Invalid choice. Please enter 1, 2, or 3.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter your choice (1-3):  1\n\nEnter your medical question:  What is downsyndrome ?\nEnter a specific medical focus area (optional, press Enter to skip):  \n"},{"name":"stdout","text":"\nProcessing question: What is downsyndrome ?\n\nGemma output:\n<start_of_turn>user\nYou are a medical expert.\nPlease answer the following medical question accurately and thoroughly.\nInclude the relevant medical focus area and any sources in your answer:\n\nQuestion: What is downsyndrome ?<end_of_turn>\n<start_of_turn>model\n## Down Syndrome: A Comprehensive Overview\n\n**Medical Focus Area:** Genetics and Developmental Disorders\n\n**Definition:** Down syndrome is a genetic disorder caused by the presence of an extra copy of chromosome 21. This extra genetic material leads to a range of physical and intellectual developmental challenges.\n\n**Causes:**\n\n* **Trisomy 21:** The most common cause, occurring when there are three copies of chromosome 21 instead of the usual two. This is a random occurrence during cell division.\n* **Translocation Down Syndrome:** A less common cause where a part of chromosome 21 breaks off and attaches to another chromosome.\n\n**Symptoms:**\n\nDown syndrome is characterized by a combination of physical and intellectual features. These can vary in severity, but common symptoms include:\n\n* **Physical Characteristics:**\n    * Upward slanting eyes\n    * Flattened facial profile\n    * Small head and short neck\n    * Single deep crease across palm of hand\n    * Hypotonia (low muscle\nTOTAL TIME ELAPSED: 461.67s\n\n=== Final Answer ===\n<start_of_turn>user\nYou are a medical expert.\nPlease answer the following medical question accurately and thoroughly.\nInclude the relevant medical focus area and any sources in your answer:\n\nQuestion: What is downsyndrome ?<end_of_turn>\n<start_of_turn>model\n## Down Syndrome: A Comprehensive Overview\n\n**Medical Focus Area:** Genetics and Developmental Disorders\n\n**Definition:** Down syndrome is a genetic disorder caused by the presence of an extra copy of chromosome 21. This extra genetic material leads to a range of physical and intellectual developmental challenges.\n\n**Causes:**\n\n* **Trisomy 21:** The most common cause, occurring when there are three copies of chromosome 21 instead of the usual two. This is a random occurrence during cell division.\n* **Translocation Down Syndrome:** A less common cause where a part of chromosome 21 breaks off and attaches to another chromosome.\n\n**Symptoms:**\n\nDown syndrome is characterized by a combination of physical and intellectual features. These can vary in severity, but common symptoms include:\n\n* **Physical Characteristics:**\n    * Upward slanting eyes\n    * Flattened facial profile\n    * Small head and short neck\n    * Single deep crease across palm of hand\n    * Hypotonia (low muscle\n\nThis interaction has been saved to 'medical_qa_history.txt'\n\n==================================================\nMEDICAL Q&A ASSISTANT\n==================================================\n1. Ask a medical question\n2. Run demonstration pipeline (with example data)\n3. Quit\n","output_type":"stream"}],"execution_count":null}]}