{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11372,"sourceType":"modelInstanceVersion","modelInstanceId":5388,"modelId":3533},{"sourceId":208024,"sourceType":"modelInstanceVersion","modelInstanceId":5388,"modelId":3533}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Goal: Program to fetch and summarize the latest AI certification / courses from web and store results in a csv file.","metadata":{}},{"cell_type":"markdown","source":"## Install dependencies ","metadata":{}},{"cell_type":"code","source":"# Install required packages\n!pip install -q -U requests beautifulsoup4 keras-nlp tensorflow transformers\nprint(\"Installation Complete\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:45:20.925222Z","iopub.execute_input":"2025-03-05T21:45:20.925503Z","iopub.status.idle":"2025-03-05T21:45:36.019429Z","shell.execute_reply.started":"2025-03-05T21:45:20.925484Z","shell.execute_reply":"2025-03-05T21:45:36.018534Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.0/186.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.8/704.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstallation Complete\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Load Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport urllib.parse\nfrom typing import List, Dict, Optional\nfrom urllib.parse import urlparse, parse_qs\nimport requests\nfrom bs4 import BeautifulSoup\nimport tensorflow as tf\nimport keras_nlp\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:45:36.020481Z","iopub.execute_input":"2025-03-05T21:45:36.020710Z","iopub.status.idle":"2025-03-05T21:45:49.611193Z","shell.execute_reply.started":"2025-03-05T21:45:36.020690Z","shell.execute_reply":"2025-03-05T21:45:49.610326Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## AI Search Engine with LLM component for summaization","metadata":{}},{"cell_type":"code","source":"class AI_Search_Engine:\n    \"\"\"\n    Comprehensive AI Certification Search and Summarization Engine\n    Optimized for Kaggle Notebook Environment\n    \"\"\"\n    \n    # CONFIGURATION BLOCK for easy updates to search and categories.\n    SEARCH_STRATEGIES = [\n        \"certification+course\",\n        \"certification+online+training\", \n        \"certification+program\"\n    ]\n    \n    CERTIFICATION_CATEGORIES = {\n        'Machine Learning': ['machine learning', 'ml', 'deep learning', 'neural network'],\n        'Data Science': ['data science', 'data analyst', 'data engineering', 'big data'],\n        'AI/ML': ['artificial intelligence', 'ai', 'machine learning', 'deep learning'],\n        'Cloud AI': ['cloud', 'aws', 'azure', 'google cloud', 'ai services'],\n        'General Tech': ['technology', 'programming', 'computer science','AI']\n    }\n    \n    # def __init__(self, model_size: str = \"gemma_instruct_2b_en\"):\n    #     \"\"\"\n    #     Initialize search engine with configurable LLM\n        \n    #     :param model_size: Size of Gemma model to load\n    #     \"\"\"\n    #     self.model = self._load_gemma_model(model_size)\n    \n    # def _load_gemma_model(self, model_preset: str):\n    #     \"\"\"\n    #     LLM COMPONENT: Load and prepare Gemma model\n        \n    #     :param model_preset: Preset model configuration\n    #     :return: Dictionary with preprocessor and model\n    #     \"\"\"\n    #     try:\n    #         preprocessor = keras_nlp.models.GemmaCausalLMPreprocessor.from_preset(model_preset)\n    #         model = keras_nlp.models.GemmaCausalLM.from_preset(model_preset)\n    #         return {'preprocessor': preprocessor, 'model': model}\n    #     except Exception as e:\n    #         print(f\"Model Loading Error: {e}\")\n    #         return None\n\n    def __init__(self, model_size: str = \"gemma_instruct_2b_en\"):\n        \"\"\"\n        Initialize search engine with configurable LLM\n        \n        :param model_size: Size of Gemma model to load\n        \"\"\"\n        # Get API key from Kaggle secrets\n        self.api_key = self._get_api_key()\n        self.model = self._load_gemma_model(model_size)\n\n    def _get_api_key(self):\n        \"\"\"\n        Retrieve Google API key from Kaggle secrets\n        \n        :return: API key string\n        \"\"\"\n        try:\n            from kaggle_secrets import UserSecretsClient\n            user_secrets = UserSecretsClient()\n            api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n            return api_key\n        except Exception as e:\n            print(f\"API Key Retrieval Error: {e}\")\n            return None\n    \n    def _load_gemma_model(self, model_preset: str):\n        \"\"\"\n        LLM COMPONENT: Load and prepare Gemma model\n        \n        :param model_preset: Preset model configuration\n        :return: Dictionary with preprocessor and model\n        \"\"\"\n        try:\n            # Set API key for Gemma model authentication\n            if self.api_key:\n                os.environ[\"GOOGLE_API_KEY\"] = self.api_key\n                print(\"API key successfully loaded from Kaggle secrets\")\n            else:\n                print(\"Warning: No API key found. Model may not authenticate properly.\")\n    \n            # Initialize Gemma preprocessor and model with API key (stored in sec)\n            preprocessor = keras_nlp.models.GemmaCausalLMPreprocessor.from_preset(\n                model_preset,\n               \n               \n            )\n            \n            model = keras_nlp.models.GemmaCausalLM.from_preset(\n                model_preset,\n            )\n            \n            return {'preprocessor': preprocessor, 'model': model}\n        except Exception as e:\n            print(f\"Model Loading Error: {e}\")\n            return None\n    \n    def _clean_text(self, text: str) -> str:\n        \"\"\"\n        Text cleaning utility for markdown compatibility\n        \n        :param text: Input text to clean\n        :return: Cleaned text\n        \"\"\"\n        return re.sub(r'\\s+', ' ', text.replace('|', '-')).strip()\n    \n    def _categorize_certification(self, title: str) -> str:\n        \"\"\"\n        Automatically categorize certification\n        \n        :param title: Certification title\n        :return: Categorized domain\n        \"\"\"\n        lower_title = title.lower()\n        return next(\n            (category for category, keywords in self.CERTIFICATION_CATEGORIES.items() \n             if any(keyword in lower_title for keyword in keywords)), \n            'Other'\n        )\n    \n    def _summarize_text(self, text: str, max_length: int = 200) -> str:\n        \"\"\"\n        SUMMARIZATION COMPONENT: Generate concise text summary\n        \n        :param text: Text to summarize\n        :param max_length: Maximum summary length\n        :return: Generated summary\n        \"\"\"\n        if not self.model:\n            return \"Summarization unavailable\"\n        \n        try:\n            prompt = f\"Summarize the following text concisely, highlighting key points:\\n\\n{text}\\n\\nSummary:\"\n            inputs = self.model['preprocessor'].generate_preprocess(prompt)\n            \n            outputs = self.model['model'].generate(\n                inputs, \n                max_length=max_length \n                #temperature=0.7\n            )\n            \n            return self.model['preprocessor'].generate_postprocess(outputs)[0]\n        except Exception as e:\n            print(f\"Summarization Error: {e}\")\n            return \"Could not generate summary\"\n    \n    def search_certifications(self, query: str) -> pd.DataFrame:\n        \"\"\"\n        FUNCTIONAL CORE: Advanced search with multiple strategies\n        \n        :param query: Search query for AI certifications\n        :return: Pandas DataFrame with search results\n        \"\"\"\n        headers = {\n            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n            'Accept-Language': 'en-US,en;q=0.5',\n        }\n        \n        results = []\n        \n        for strategy in self.SEARCH_STRATEGIES:\n            search_url = f\"https://duckduckgo.com/html/?q={urllib.parse.quote(query)}+{strategy}\"\n            ##\n            try:\n                response = requests.get(search_url, headers=headers, timeout=10)\n                \n                if response.status_code != 200:\n                    print(f\"Search failed for {search_url}\")\n                    continue\n                \n                soup = BeautifulSoup(response.text, 'html.parser')\n                result_selectors = ['div.result__body', 'div.result', 'div.web-result']\n                \n                for selector in result_selectors:\n                    search_results = soup.select(selector)\n                    if search_results:\n                        break\n                          \n                for result in search_results[:10]:\n                    try:\n                        title = result.find(['h2', 'a'], class_=['result__title', 'result-link']).get_text(strip=True)\n                        link = result.find(['a'], class_=['result__url', 'result-link'])['href']\n                        snippet = result.find(['a', 'div'], class_=['result__snippet', 'result-snippet']).get_text(strip=True)\n                \n                        # Remove the DuckDuckGo redirect prefix\n                        if link.startswith(\"//duckduckgo.com/l/?uddg=\"):\n                            parsed_url = urlparse(link)\n                            query_params = parse_qs(parsed_url.query)\n                            if \"uddg\" in query_params:\n                                link = query_params[\"uddg\"][0]  # Extract the target URL\n                \n                        results.append({\n                            'title': self._clean_text(title),\n                            'link': link,\n                            'snippet': snippet,\n                            'category': self._categorize_certification(title),\n                            'summary': self._summarize_text(snippet)\n                        })\n                   \n                    except Exception as result_error:\n                        print(f\"Result extraction error: {result_error}\")\n            \n            except Exception as e:\n                print(f\"Search error: {e}\")\n        \n        return pd.DataFrame(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:48:36.694562Z","iopub.execute_input":"2025-03-05T21:48:36.694844Z","iopub.status.idle":"2025-03-05T21:48:36.707792Z","shell.execute_reply.started":"2025-03-05T21:48:36.694821Z","shell.execute_reply":"2025-03-05T21:48:36.706932Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Main Entry","metadata":{}},{"cell_type":"code","source":"def main():\n    \"\"\"\n    Entry Point\n    \"\"\"\n    search_engine = AI_Search_Engine()\n    \n    # Interactive search for AI certifications\n    query = input(\"Enter AI Certification Search Query: \")\n    results_df = search_engine.search_certifications(query)\n    \n    # Display results\n    print(\"\\n 🔍 AI Certification Search Results:\")\n    print(results_df)\n    \n    # Save to CSV for further analysis\n    results_df.to_csv(f\"{query.replace(' ', '_')}_ai_certifications.csv\", index=False)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:48:41.045819Z","iopub.execute_input":"2025-03-05T21:48:41.046102Z","iopub.status.idle":"2025-03-05T21:50:10.868580Z","shell.execute_reply.started":"2025-03-05T21:48:41.046080Z","shell.execute_reply":"2025-03-05T21:50:10.867213Z"}},"outputs":[{"name":"stdout","text":"API key successfully loaded from Kaggle secrets\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter AI Certification Search Query:  RAG\n"},{"name":"stdout","text":"Summarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\nSummarization Error: Exception encountered when calling GemmaTokenizer.call().\n\n\u001b[1mAttempt to convert a value ({'token_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([     2, 156910,    889, ...,      0,      0,      0], dtype=int32)>, 'padding_mask': <tf.Tensor: shape=(1024,), dtype=bool, numpy=array([ True,  True,  True, ..., False, False, False])>}) with an unsupported type (<class 'dict'>) to a Tensor.\u001b[0m\n\nArguments received by GemmaTokenizer.call():\n  • inputs={'token_ids': 'tf.Tensor(shape=(1024,), dtype=int32)', 'padding_mask': 'tf.Tensor(shape=(1024,), dtype=bool)'}\n  • args=<class 'inspect._empty'>\n  • training=None\n  • kwargs=<class 'inspect._empty'>\n\n 🔍 AI Certification Search Results:\n                                                title  \\\n0   Building and Evaluating Advanced RAG Applications   \n1   Free RAG Course Online with Certificate (2025)...   \n2   Introduction to Retrieval Augmented Generation...   \n3   Retrieval Augmented Generation LlamaIndex & La...   \n4   Fundamentals of AI Agents Using RAG and LangCh...   \n5   Introduction to Retrieval Augmented Generation...   \n6       7 Free Courses to Master RAG - turingpost.com   \n7   Free Advanced RAG Certification course with Ac...   \n8               Best RAG Courses - learnprompting.org   \n9   Master RAG: Ultimate Retrieval-Augmented Gener...   \n10  Introduction to Retrieval Augmented Generation...   \n11  Free RAG Course Online with Certificate (2025)...   \n12  Fundamentals of AI Agents Using RAG and LangCh...   \n13  Retrieval Augmented Generation LlamaIndex & La...   \n14              Best RAG Courses - learnprompting.org   \n15  Introduction to Retrieval Augmented Generation...   \n16      7 Free Courses to Master RAG - turingpost.com   \n17  Free Advanced RAG Certification course with Ac...   \n18  300+ Retrieval Augmented Generation (RAG) Onli...   \n19  Top Retrieval Augmented Generation (RAG) Cours...   \n20  Retrieval Augmented Generation LlamaIndex & La...   \n21  Free RAG Course Online with Certificate (2025)...   \n22  IBM: Mastering Generative AI: Agents with RAG ...   \n23  Building and Evaluating Advanced RAG Applications   \n24  Fundamentals of AI Agents Using RAG and LangCh...   \n25  Retrieval Augmented Generation (RAG) Introduct...   \n26  Introduction to Retrieval Augmented Generation...   \n27  Free Advanced RAG Certification course with Ac...   \n28              Best RAG Courses - learnprompting.org   \n29  Applied Generative AI with Langchain and RAG T...   \n\n                                                 link  \\\n0   https://www.deeplearning.ai/short-courses/buil...   \n1   https://www.mygreatlearning.com/academy/learn-...   \n2   https://www.coursera.org/learn/introduction-to...   \n3             https://learn.activeloop.ai/courses/rag   \n4   https://www.coursera.org/learn/fundamentals-of...   \n5   https://www.coursera.org/projects/introduction...   \n6   https://www.turingpost.com/p/7-free-courses-to...   \n7   https://www.llamaindex.ai/blog/join-thousands-...   \n8         https://learnprompting.org/blog/rag-courses   \n9   https://www.udemy.com/course/llm-retrieval-aug...   \n10  https://www.coursera.org/learn/introduction-to...   \n11  https://www.mygreatlearning.com/academy/learn-...   \n12  https://www.coursera.org/learn/fundamentals-of...   \n13            https://learn.activeloop.ai/courses/rag   \n14        https://learnprompting.org/blog/rag-courses   \n15  https://www.coursera.org/projects/introduction...   \n16  https://www.turingpost.com/p/7-free-courses-to...   \n17  https://www.llamaindex.ai/blog/join-thousands-...   \n18           https://www.classcentral.com/subject/rag   \n19  https://www.udemy.com/topic/retrieval-augmente...   \n20            https://learn.activeloop.ai/courses/rag   \n21  https://www.mygreatlearning.com/academy/learn-...   \n22  https://www.edx.org/learn/computer-science/ibm...   \n23  https://www.deeplearning.ai/short-courses/buil...   \n24  https://www.coursera.org/learn/fundamentals-of...   \n25  https://training.linuxfoundation.org/training/...   \n26  https://www.coursera.org/learn/introduction-to...   \n27  https://medium.com/llamaindex-blog/join-thousa...   \n28        https://learnprompting.org/blog/rag-courses   \n29  https://www.edureka.co/applied-generative-ai-l...   \n\n                                              snippet category  \\\n0   To successfully implementRAG, it is essential ...    Other   \n1   FreeRAGCoursewith Certificate Introduction ToR...    Other   \n2   In thiscourse, we start with the concepts and ...    Other   \n3   The Foundational ModelCertificationis your ess...    AI/ML   \n4   Thecoursemay not offer an audit option. You ca...    AI/ML   \n5   Receive training from industry experts; ... cr...    Other   \n6   Here are 7 freecoursesthat can help you master...    Other   \n7   LlamaIndex is proud to collaborate with Active...    AI/ML   \n8   DetailedCourseReviews Retrieval Augmented Gene...    Other   \n9   Thiscourseis a deep dive into the world of Ret...    Other   \n10  By the end of this course, you'll be able to d...    Other   \n11  FreeRAGCourse with Certificate Introduction To...    Other   \n12  This Fundamentals of Building AI Agents usingR...    AI/ML   \n13  The Foundational ModelCertificationis your ess...    AI/ML   \n14  Best Suited For: This course is designed for a...    Other   \n15  Receivetrainingfrom industry experts; ... crea...    Other   \n16  Introduction to Retrieval Augmented Generation...    Other   \n17  This comprehensive course takes a hands-on app...    AI/ML   \n18  Bestonlinecourses in Retrieval Augmented Gener...    Other   \n19  RAG(Retrieval Augmented Generation) with Vecto...    Other   \n20  The Foundational ModelCertificationis your ess...    AI/ML   \n21  FreeRAGCourse with Certificate Introduction To...    Other   \n22  Dive into the world of retrieval augmented gen...    AI/ML   \n23  To successfully implementRAG, it is essential ...    Other   \n24  You'll then learn about theRAGprocess, the Den...    AI/ML   \n25  Module 1: LLM Overview - Lab: Building an LLM ...    Other   \n26  Demonstrate the use ofRAGApplications in a ran...    Other   \n27  RAGAgents: This module focuses on the creation...    Other   \n28  Best Suited For: This course is designed for a...    Other   \n29  Enroll now in this applied generative aiprogra...    AI/ML   \n\n                       summary  \n0   Could not generate summary  \n1   Could not generate summary  \n2   Could not generate summary  \n3   Could not generate summary  \n4   Could not generate summary  \n5   Could not generate summary  \n6   Could not generate summary  \n7   Could not generate summary  \n8   Could not generate summary  \n9   Could not generate summary  \n10  Could not generate summary  \n11  Could not generate summary  \n12  Could not generate summary  \n13  Could not generate summary  \n14  Could not generate summary  \n15  Could not generate summary  \n16  Could not generate summary  \n17  Could not generate summary  \n18  Could not generate summary  \n19  Could not generate summary  \n20  Could not generate summary  \n21  Could not generate summary  \n22  Could not generate summary  \n23  Could not generate summary  \n24  Could not generate summary  \n25  Could not generate summary  \n26  Could not generate summary  \n27  Could not generate summary  \n28  Could not generate summary  \n29  Could not generate summary  \n","output_type":"stream"}],"execution_count":7}]}